{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4X Study Dashboard\n",
    "This notebook is used to analyze data from the 4X study conducted in March 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Global Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import math\n",
    "import json\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette\n",
    "sns.set(font_scale=1.5, style='whitegrid')\n",
    "# sns.set_palette(\"cubehelix\")\n",
    "sns.set_palette(sns.cubehelix_palette(rot=-.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Google Sheets Auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup connection\n",
    "scope = ['https://spreadsheets.google.com/feeds']\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name('credential.json', scope)\n",
    "gc = gspread.authorize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_google_sheet_data(url, new_col_names=[]):\n",
    "    \"\"\"\n",
    "    Loads in and returns post-study as a Pandas DataFrame with header remapped according to values above.\n",
    "    \n",
    "    Inputs:\n",
    "        url (string): url of spreadsheet to load in\n",
    "        new_col_names (list): list of strings for new column names\n",
    "    \n",
    "    Returns:\n",
    "        (DataFrame): Pandas DataFrame with header remapped above\n",
    "    \"\"\"\n",
    "    url_connection = gc.open_by_url(url)\n",
    "    raw_data = url_connection.get_worksheet(0).get_all_values()\n",
    "    \n",
    "    output_df = pd.DataFrame(raw_data[1:], columns=raw_data[0])\n",
    "    if len(new_col_names) > 0:\n",
    "        output_df.columns = new_col_names\n",
    "\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data from LES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study Length: 12 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "# URL for hosted Parse server\n",
    "url = 'https://les-expand.herokuapp.com/parse/classes/'\n",
    "\n",
    "# shared header and data for Parse\n",
    "header = {'X-Parse-Application-Id': 'PkngqKtJygU9WiQ1GXM9eC0a17tKmioKKmpWftYr'}\n",
    "data = {'limit': '20000'}\n",
    "\n",
    "# study start and end\n",
    "start_time = '2018-08-27 05:00:00'\n",
    "mid_time = '2018-09-02 05:00:00'\n",
    "end_time = '2018-09-08 05:00:00'\n",
    "\n",
    "start_time_date = datetime.strptime(start_time, '%Y-%m-%d %H:%M:%S')\n",
    "mid_time_date = datetime.strptime(mid_time, '%Y-%m-%d %H:%M:%S')\n",
    "end_time_date = datetime.strptime(end_time, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print('Study Length: {}'.format(end_time_date - start_time_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_url, header, data, start_time, end_time):\n",
    "    \"\"\"\n",
    "    Loads in all needed tables from database, given url.\n",
    "    \n",
    "    Input: \n",
    "        base_url (string): url to pull data from\n",
    "        header (dict): application id and other auth\n",
    "        data (dict): data to pass into query\n",
    "        start_time (datetime): start time for data\n",
    "        end_time (datetime): end time for data \n",
    "    \n",
    "    Return:\n",
    "        (dict): dict where keys are collection names and values are Pandas objects containing data\n",
    "    \"\"\"\n",
    "    # declare collection list\n",
    "    collection_list = ['_User', 'ServerLog', 'DebugLog', 'ForYouViewLog', 'ApplicationHeartbeat',\n",
    "                       'TaskLocations', 'LocationTypeMetadata', 'beacons', 'EnRouteLocations',\n",
    "                       'AtLocationNotificationsSent', 'AtLocationNotificationResponses',\n",
    "                       'EnRouteNotificationsSent', 'EnRouteNotificationResponses',\n",
    "                       'AtDistanceNotificationsSent', 'AtDistanceNotificationResponses']\n",
    "    \n",
    "    # loop through and load data for each collection\n",
    "    output = {}\n",
    "    for collection in tqdm(collection_list):\n",
    "        current_response = requests.get(base_url + collection, headers=header, data=data)\n",
    "\n",
    "        current_data = pd.DataFrame(current_response.json()['results'])\n",
    "        if len(current_data) != 0 and collection not in ['LocationTypeMetadata', 'EnRouteLocations']:\n",
    "            current_data['createdAt'] = pd.to_datetime(current_data['createdAt'])\n",
    "            current_data['updatedAt'] = pd.to_datetime(current_data['updatedAt'])\n",
    "            \n",
    "            if collection != '_User':\n",
    "                current_data = current_data[(current_data['createdAt'] >= start_time) & (current_data['createdAt'] < end_time)]\n",
    "\n",
    "        output[collection] = current_data\n",
    "    \n",
    "    return output\n",
    "\n",
    "def load_data_parallel(url):\n",
    "    return load_data(url, header, data, start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7426fe918e645c3a6f898192357418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fetch log data\n",
    "raw_data = load_data(url, header, data, start_time, end_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Study Survey Data TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_dict = {\n",
    "    '1: Very invaluable': 1,\n",
    "    '2: Invaluable': 2,\n",
    "    '3: Neutral': 3,\n",
    "    '4: Valuable': 4,\n",
    "    '5: Very valuable': 5,\n",
    "    '1: Never': 1,\n",
    "    '2: Rarely, in less than 10% of the notifications': 2,\n",
    "    '3: Occasionally, in about 30% of the notifications': 3,\n",
    "    '4: Sometimes, in about 50% of the notifications': 4,\n",
    "    '5: Frequently, in about 70% of the notifications': 5,\n",
    "    '6: Usually, in about 90% of the notifications': 6,\n",
    "    '7: Every time I was notified': 7,\n",
    "    '1: Not likely': 1,\n",
    "    '2: Somewhat unlikely': 2,\n",
    "    '3: Neutral': 3,\n",
    "    '4: Somewhat likely': 4,\n",
    "    '5: Very likely': 5,\n",
    "    '1: Not disruptive, easy to do and continue on with my routine': 1,\n",
    "    '2: Rarely disruptive': 2,\n",
    "    '3: Occasionally disruptive': 3,\n",
    "    '4: Moderately disruptive': 4,\n",
    "    '5: A great deal disruptive, I had to stop what I was doing to answer': 5,\n",
    "    '0: N/A': 0,\n",
    "    '1: Far fewer than I would have liked': 1,\n",
    "    '2: Fewer than I would have liked': 2,\n",
    "    '3: About correct for the number I would have liked': 3,\n",
    "    '4: More than I would have liked': 4,\n",
    "    '5: Far more than I would have liked': 5,\n",
    "    '': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>email_address</th>\n",
       "      <th>name</th>\n",
       "      <th>overall_value</th>\n",
       "      <th>overall_disruption</th>\n",
       "      <th>future_use</th>\n",
       "      <th>overall_experience</th>\n",
       "      <th>explore_respond</th>\n",
       "      <th>explore_not_respond</th>\n",
       "      <th>explore_disruption</th>\n",
       "      <th>expand_info_going</th>\n",
       "      <th>expand_info_going_notgo</th>\n",
       "      <th>expand_info_notuseful</th>\n",
       "      <th>expand_info_altprefs</th>\n",
       "      <th>expand_info_disruption</th>\n",
       "      <th>expand_info_number_notif</th>\n",
       "      <th>exploit_atloc</th>\n",
       "      <th>exploit_enroute</th>\n",
       "      <th>exploit_disruption</th>\n",
       "      <th>miscellaneous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/18/2018 23:17:30</td>\n",
       "      <td>allisonsun2018@u.northwestern.edu</td>\n",
       "      <td>Allison Sun</td>\n",
       "      <td>3</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>I liked being notified for free food in Ford a...</td>\n",
       "      <td>Always responded to the notifications for Ford...</td>\n",
       "      <td>Can't think of any instances when I didn't res...</td>\n",
       "      <td>2</td>\n",
       "      <td>Only went the free food places in ford because...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Coffee shops that I frequent more like Peets a...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp                      email_address         name  \\\n",
       "0  3/18/2018 23:17:30  allisonsun2018@u.northwestern.edu  Allison Sun   \n",
       "\n",
       "   overall_value  overall_disruption  future_use  \\\n",
       "0              3            1.666667           4   \n",
       "\n",
       "                                  overall_experience  \\\n",
       "0  I liked being notified for free food in Ford a...   \n",
       "\n",
       "                                     explore_respond  \\\n",
       "0  Always responded to the notifications for Ford...   \n",
       "\n",
       "                                 explore_not_respond  explore_disruption  \\\n",
       "0  Can't think of any instances when I didn't res...                   2   \n",
       "\n",
       "                                   expand_info_going expand_info_going_notgo  \\\n",
       "0  Only went the free food places in ford because...                     N/A   \n",
       "\n",
       "  expand_info_notuseful                               expand_info_altprefs  \\\n",
       "0                   N/A  Coffee shops that I frequent more like Peets a...   \n",
       "\n",
       "   expand_info_disruption  expand_info_number_notif exploit_atloc  \\\n",
       "0                       2                         2           N/A   \n",
       "\n",
       "  exploit_enroute  exploit_disruption miscellaneous  \n",
       "0             N/A                   0            -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup 4X post-survey data\n",
    "url_4x = 'https://docs.google.com/spreadsheets/d/1rCH32DdAfnOSoe-qNIQgO7rQei2VATHxLlGfP0bCNg8/edit#gid=339656711'\n",
    "cols_4x = [\n",
    "    'timestamp',\n",
    "    'email_address',\n",
    "    'name',\n",
    "    'overall_value',\n",
    "    'overall_disruption',\n",
    "    'future_use',\n",
    "    'overall_experience',\n",
    "    'explore_respond',\n",
    "    'explore_not_respond',\n",
    "    'explore_disruption',\n",
    "    'expand_info_going',\n",
    "    'expand_info_going_notgo',\n",
    "    'expand_info_notuseful',\n",
    "    'expand_info_altprefs',\n",
    "    'expand_info_disruption',\n",
    "    'expand_info_number_notif',\n",
    "    'exploit_atloc',\n",
    "    'exploit_enroute',\n",
    "    'exploit_disruption',\n",
    "    'miscellaneous'\n",
    "]\n",
    "post_study_4x = load_google_sheet_data(url_4x, new_col_names=cols_4x)\n",
    "post_study_4x.replace(to_replace=replacement_dict, inplace=True)\n",
    "post_study_4x['overall_disruption'] = (2/3) * post_study_4x['overall_disruption'] + (1/3)\n",
    "\n",
    "# remove bad users\n",
    "post_study_4x = post_study_4x[post_study_4x['email_address'] != 'jamiekuhn2019@u.northwestern.edu']\n",
    "\n",
    "post_study_4x.to_csv('./analysis/post_study_4x.csv', index=False)\n",
    "post_study_4x.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup\n",
    "This section of the notebook is used to monitor the data coming in from the study. Some measures we see here may be used within the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_at_location(tasklocations, atlocnotif, atlocresp):\n",
    "    \"\"\"\n",
    "    Sets up a Pandas DataFrame with (1) TaskLocation, (2) NotificationSent, and (3) NotificationResponse data\n",
    "    merged together for AtLocation case.\n",
    "    \n",
    "    Input:\n",
    "        tasklocations (DataFrame): DataFrame of TaskLocations\n",
    "        atlocnotif (DataFrame): DataFrame of AtLocationNotificationsSent\n",
    "        atlocresp (DataFrame): DataFrame of AtLocationNotificationResponses\n",
    "    \n",
    "    Return:\n",
    "        (DataFrame): merged DataFrame of inputs\n",
    "    \"\"\"\n",
    "    # get AtLocationNotifications without duplicates\n",
    "    atlocnotif.sort_values('createdAt', inplace=True)\n",
    "    atlocnotif.drop_duplicates(subset=['taskLocationId', 'vendorId'], keep='last', inplace=True)\n",
    "    atlocnotif.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "\n",
    "    # get AtLocationNotificationResponses without duplicates\n",
    "    atlocresp.sort_values('createdAt', inplace=True)\n",
    "    atlocresp.drop_duplicates(subset=['taskLocationId', 'vendorId'], keep='last', inplace=True)\n",
    "    atlocresp.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "    \n",
    "    # combine AtLocation notifications and responses, with some data from TaskLocations\n",
    "    atloc = atlocnotif.merge(tasklocations[['objectId', 'locationType', 'locationName', 'beaconId']],\n",
    "                             how='inner', left_on='taskLocationId', right_on='objectId')\n",
    "    atloc = atloc.merge(atlocresp[['question', 'response', 'timestamp', 'taskLocationId', 'vendorId']],\n",
    "                        how='left', on=['taskLocationId', 'vendorId'])\n",
    "    \n",
    "    # clean columns\n",
    "    del atloc['objectId']\n",
    "    atloc.rename(columns={'timestamp_x': 'notificationTimestamp', 'timestamp_y': 'responseTimestamp'},\n",
    "                 inplace=True)\n",
    "    \n",
    "    # fill blank columns\n",
    "    atloc[['question', 'response']] = atloc[['question', 'response']].fillna(value='Missed Notification')\n",
    "    atloc[['distanceToLocation', 'responseTimestamp']] = atloc[['distanceToLocation', 'responseTimestamp']].fillna(value=-1)\n",
    "\n",
    "    # type columns\n",
    "    atloc_int_cols = ['gmtOffset','notificationTimestamp', 'responseTimestamp']\n",
    "    atloc[atloc_int_cols] = atloc[atloc_int_cols].apply(lambda x: x.astype(np.int64))\n",
    "    \n",
    "    # add remappedResponses column \n",
    "    invalid_responses = ['I don\\'t know', 'com.apple.UNNotificationDismissActionIdentifier', 'Missed Notification']\n",
    "    atloc['remappedResponses'] = atloc['response']\n",
    "    atloc.loc[~atloc['remappedResponses'].isin(invalid_responses), 'remappedResponses'] = 'Valid Response'\n",
    "    atloc.loc[atloc['remappedResponses'] == 'com.apple.UNNotificationDismissActionIdentifier', 'remappedResponses'] = 'Dismissed Notification'\n",
    "    atloc.loc[atloc['remappedResponses'] == 'I don\\'t know', 'remappedResponses'] = '\"I don\\'t know\" Response'\n",
    "    \n",
    "    # reorder columns\n",
    "    atloc_col_ordering = ['taskLocationId', 'vendorId', 'beaconId', 'distanceToLocation',\n",
    "                          'locationType', 'locationName','gmtOffset', 'notificationTimestamp', 'notificationString',\n",
    "                          'question', 'response', 'remappedResponses', 'responseTimestamp']\n",
    "    atloc = atloc[atloc_col_ordering]\n",
    "    \n",
    "    return atloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_at_distance(tasklocations, atdistnotif, atdistresp):\n",
    "    \"\"\"\n",
    "    Sets up a Pandas DataFrame with (1) TaskLocation, (2) NotificationSent, and (3) NotificationResponse data\n",
    "    merged together for AtDistance case.\n",
    "    \n",
    "    Input:\n",
    "        tasklocations (DataFrame): DataFrame of TaskLocations\n",
    "        atdistnotif (DataFrame): DataFrame of AtDistanceNotificationsSent\n",
    "        atdistresp (DataFrame): DataFrame of AtDistanceNotificationResponses\n",
    "    \n",
    "    Return:\n",
    "        (DataFrame): merged DataFrame of inputs\n",
    "    \"\"\"\n",
    "    # get AtDistanceNotifications without duplicates\n",
    "    atdistnotif.sort_values('createdAt', inplace=True)\n",
    "    atdistnotif.drop_duplicates(subset=['taskLocationId', 'vendorId'], keep='last', inplace=True)\n",
    "    atdistnotif.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "\n",
    "    # get AtDistanceNotificationResponses without duplicates\n",
    "    atdistresp.sort_values('createdAt', inplace=True)\n",
    "    atdistresp.drop_duplicates(subset=['taskLocationId', 'vendorId'], keep='last', inplace=True)\n",
    "    atdistresp.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "    \n",
    "    # combine AtDistance notifications and responses, with some data from TaskLocations\n",
    "    atdist = atdistnotif.merge(tasklocations[['objectId', 'beaconId', 'locationName']],\n",
    "                               how='inner', left_on='taskLocationId', right_on='objectId')\n",
    "    atdist = atdist.merge(atdistresp[['emaResponse', 'timestamp', 'taskLocationId', 'vendorId']],\n",
    "                          how='left', on=['taskLocationId', 'vendorId'])\n",
    "    \n",
    "    # clean columns\n",
    "    del atdist['objectId']\n",
    "    atdist.rename(columns={'timestamp_x': 'notificationTimestamp', 'timestamp_y': 'responseTimestamp'}, inplace=True)\n",
    "\n",
    "    atdist_col_ordering = ['taskLocationId', 'vendorId', 'beaconId', 'distanceToLocation', 'bearingToLocation',\n",
    "                           'locationType', 'locationName', 'notificationDistance', 'sentBy', 'infoIncluded',\n",
    "                           'gmtOffset', 'notificationTimestamp', 'emaResponse', 'responseTimestamp']\n",
    "    atdist = atdist[atdist_col_ordering]\n",
    "    \n",
    "    # fill blank columns\n",
    "    atdist['emaResponse'] = atdist['emaResponse'].fillna(value='Missed Notification')\n",
    "    atdist['responseTimestamp'] = atdist['responseTimestamp'].fillna(value=-1)\n",
    "    \n",
    "    # remap columns\n",
    "    atdist.loc[atdist['emaResponse'] == 'com.apple.UNNotificationDismissActionIdentifier', 'emaResponse'] = 'Dismissed Notification'\n",
    "\n",
    "    # type columns\n",
    "    atdist_int_cols = ['gmtOffset','notificationTimestamp', 'responseTimestamp']\n",
    "    atdist[atdist_int_cols] = atdist[atdist_int_cols].apply(lambda x: x.astype(np.int64))\n",
    "    \n",
    "    return atdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_atdist_atloc(merged_atdist, merged_atloc, time_threshold=14400):\n",
    "    \"\"\"\n",
    "    Merges at-distance and at-location into one dataframe.\n",
    "        If a corresponding match between at-distance and at-location cannot be found, function will attempt to use next instance within a time threshold.\n",
    "    \n",
    "    Input:\n",
    "        merged_atdist (DataFrame): DataFrame of merged AtDistanceNotificationsSent and AtDistanceNotificationsResponses with duplicates removed\n",
    "        merged_atloc (DataFrame): DataFrame of AtLocationNotificationSent and AtLocationNotificationResponses with duplicates removed\n",
    "        time_thresold (number): limit on how far forward to look for an at-location response, in seconds (default to 4 hours)\n",
    "    \"\"\"\n",
    "    merged_output_df = deepcopy(merged_atdist)\n",
    "    merged_output_df['merge_target_tasklocationid'] = ''\n",
    "    \n",
    "    # check if there is a direct match for current row. if not, see if user went to next instance within time threshold\n",
    "    for index, row in merged_output_df.iterrows():\n",
    "        # attempt to find a direct match and add\n",
    "        target_vendorid = row['vendorId']\n",
    "        target_tasklocationid = row['taskLocationId']\n",
    "        direct_match = merged_atloc[(merged_atloc['vendorId'] == target_vendorid) &\n",
    "                                    (merged_atloc['taskLocationId'] == target_tasklocationid)]\n",
    "        \n",
    "        if len(direct_match) > 0:\n",
    "            merged_output_df.at[index, 'merge_target_tasklocationid'] = target_tasklocationid\n",
    "        else:\n",
    "            # is no match is found, try next instance of same locationName within 1 hour\n",
    "            target_locationname = row['locationName']\n",
    "            current_timestamp = row['notificationTimestamp']\n",
    "            next_instance_data = merged_atloc[(merged_atloc['vendorId'] == target_vendorid) &\n",
    "                                              (merged_atloc['locationName'] == target_locationname) &\n",
    "                                              (merged_atloc['notificationTimestamp'] > current_timestamp) &\n",
    "                                              (merged_atloc['notificationTimestamp'] <= current_timestamp + time_threshold)].reset_index(drop=True)\n",
    "            \n",
    "            if len(next_instance_data) > 0:\n",
    "                merged_output_df.at[index, 'merge_target_tasklocationid'] = next_instance_data.iloc[0]['taskLocationId']\n",
    "                \n",
    "    # run merge with new merge targets\n",
    "    merged_output_df = merged_output_df.merge(merged_atloc, how='left',\n",
    "                                              left_on=['vendorId', 'merge_target_tasklocationid'],\n",
    "                                              right_on=['vendorId', 'taskLocationId'])\n",
    "    merged_output_df['remappedResponses'].fillna(value='Did Not Go', inplace=True)\n",
    "    \n",
    "    # clean up columns and return\n",
    "    column_remapping = {\n",
    "        'taskLocationId_x': 'atdist_taskLocationId',\n",
    "        'taskLocationId_y': 'atloc_taskLocationId',\n",
    "        'beaconId_x': 'beaconId',\n",
    "        'distanceToLocation_x': 'atdist_distanceToLocation',\n",
    "        'distanceToLocation_y': 'atloc_distanceToLocation',\n",
    "        'locationType_x': 'locationType',\n",
    "        'locationName_x': 'locationName',\n",
    "        'gmtOffset_x': 'gmtOffset',\n",
    "        'notificationTimestamp_x': 'atdist_notificationTimestamp',\n",
    "        'notificationTimestamp_y': 'atloc_notificationTimestamp',\n",
    "        'responseTimestamp_x': 'atdist_responseTimestamp',\n",
    "        'responseTimestamp_y': 'atloc_responseTimestamp',\n",
    "        'date_x': 'date',\n",
    "        'week_x': 'week',\n",
    "        'timestamp_x': 'atdist_NotificationTimestamp',\n",
    "        'timestamp_y': 'responseTimestamp'\n",
    "    }\n",
    "    merged_output_df.drop(['beaconId_y', 'locationType_y', 'locationName_y', 'gmtOffset_y', 'date_y', 'week_y'], axis=1, inplace=True)\n",
    "    merged_output_df.rename(columns=column_remapping, inplace=True)\n",
    "    \n",
    "    return merged_output_df        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_en_route(enroutelocations, enroutenotif, enrouteresp):\n",
    "    \"\"\"\n",
    "    Sets up a Pandas DataFrame with (1) EnRouteLocations, (2) NotificationSent, and (3) NotificationResponse data\n",
    "    merged together for EnRoute case.\n",
    "    \n",
    "    Input:\n",
    "        enroutelocations (DataFrame): DataFrame of EnRouteLocations\n",
    "        enroutenotif (DataFrame): DataFrame of EnRouteNotificationsSent\n",
    "        enrouteresp (DataFrame): DataFrame of EnRouteNotificationResponses\n",
    "    \n",
    "    Return:\n",
    "        (DataFrame): merged DataFrame of inputs\n",
    "    \"\"\"\n",
    "    # get EnRouteNotifications without duplicates\n",
    "    enroutenotif.sort_values('createdAt', inplace=True)\n",
    "    enroutenotif['date'] = pd.to_datetime(enroutenotif['timestamp'] + enroutenotif['gmtOffset'], unit='s').dt.date\n",
    "    enroutenotif['hour'] = pd.to_datetime(enroutenotif['timestamp'] + enroutenotif['gmtOffset'], unit='s').dt.hour\n",
    "    enroutenotif['minute'] = pd.to_datetime(enroutenotif['timestamp'] + enroutenotif['gmtOffset'], unit='s').dt.minute\n",
    "    enroutenotif['half_hour'] = enroutenotif['minute'].apply(lambda x: 0 if x <= 30 else 30)\n",
    "    \n",
    "    enroutenotif.drop_duplicates(subset=['date', 'hour', 'half_hour', 'vendorId'], keep='last', inplace=True)\n",
    "    enroutenotif.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "\n",
    "    # get EnRouteNotificationsResponses without duplicates\n",
    "    enrouteresp.sort_values('createdAt', inplace=True)\n",
    "    enrouteresp['date'] = pd.to_datetime(enrouteresp['timestamp'] + enrouteresp['gmtOffset'], unit='s').dt.date\n",
    "    enrouteresp['hour'] = pd.to_datetime(enrouteresp['timestamp'] + enrouteresp['gmtOffset'], unit='s').dt.hour\n",
    "    enrouteresp['minute'] = pd.to_datetime(enrouteresp['timestamp'] + enrouteresp['gmtOffset'], unit='s').dt.minute\n",
    "    enrouteresp['half_hour'] = enrouteresp['minute'].apply(lambda x: 0 if x <= 30 else 30)\n",
    "    \n",
    "    enrouteresp.drop_duplicates(subset=['date', 'hour', 'half_hour', 'vendorId'], keep='last', inplace=True)\n",
    "    enrouteresp.drop(['objectId', 'createdAt', 'updatedAt'], axis=1, inplace=True)\n",
    "    \n",
    "    # combine EnRouteNotifications and responses, with some data from EnRouteLocations\n",
    "    enroute = enroutenotif.merge(enroutelocations[['objectId', 'locationName', 'locationType']],\n",
    "                               how='inner', left_on='enRouteLocationId', right_on='objectId')\n",
    "    enroute = enroute.merge(enrouteresp[['questionResponse', 'timestamp', 'enRouteLocationId', 'vendorId',\n",
    "                                         'date', 'hour', 'half_hour']],\n",
    "                            how='left', on=['enRouteLocationId', 'vendorId', 'date', 'hour', 'half_hour'])\n",
    "    \n",
    "    # clean columns\n",
    "    del enroute['objectId']\n",
    "    enroute.rename(columns={'timestamp_x': 'notificationTimestamp', 'timestamp_y': 'responseTimestamp'}, inplace=True)\n",
    "\n",
    "    enroute_col_ordering = ['enRouteLocationId', 'vendorId', 'distanceToLocation', 'locationType', 'locationName',\n",
    "                           'gmtOffset', 'notificationTimestamp', 'questionResponse', 'responseTimestamp']\n",
    "    enroute = enroute[enroute_col_ordering]\n",
    "    \n",
    "    # fill blank columns\n",
    "    enroute['questionResponse'] = enroute['questionResponse'].fillna(value='Missed Notification')\n",
    "    enroute.loc[enroute['questionResponse'] == 'com.apple.UNNotificationDismissActionIdentifier', 'questionResponse'] = 'Dismissed Notification'\n",
    "    \n",
    "    enroute['responseTimestamp'] = enroute['responseTimestamp'].fillna(value=-1)\n",
    "    \n",
    "     # add validResponse column \n",
    "    invalid_responses = ['I don\\'t know', 'com.apple.UNNotificationDismissActionIdentifier', 'Missed Notification']\n",
    "    enroute['remappedResponses'] = enroute['questionResponse']\n",
    "    enroute.loc[~enroute['remappedResponses'].isin(invalid_responses), 'remappedResponses'] = 'Valid Response'\n",
    "    enroute.loc[enroute['remappedResponses'] == 'I don\\'t know', 'remappedResponses'] = '\"I don\\'t know\" Response'\n",
    "\n",
    "    # type columns\n",
    "    enroute_int_cols = ['gmtOffset','notificationTimestamp', 'responseTimestamp']\n",
    "    enroute[enroute_int_cols] = enroute[enroute_int_cols].apply(lambda x: x.astype(np.int64))\n",
    "    \n",
    "    return enroute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dead_apps(serverlog):\n",
    "    \"\"\"\n",
    "    Returns a list of lists for dead apps that server has notified.\n",
    "    \n",
    "    Input: \n",
    "        server (DataFrame): DataFrame of ServerLog\n",
    "    \n",
    "    Return:\n",
    "        (list of lists of strings): all dead applications notified via push\n",
    "    \"\"\"\n",
    "    notify_log_strings = serverlog[serverlog['logString'].str.contains('Notified dead')]['logString']\n",
    "    deadapp_notif_list = list(notify_log_strings.apply(lambda x: x[x.find('[') + 1:-1].split(', ')))\n",
    "    return deadapp_notif_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_scaffolds = {}\n",
    "for index, row in raw_data['LocationTypeMetadata'].iterrows():\n",
    "    location_scaffolds[row['locationType']] = row['scaffold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Data Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables from downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4X | User Count: 20\n",
      "4X | At location notifications: 250, At location responses: 71\n",
      "4X | At distance notifications: 129, At distance responses: 69\n",
      "4X | En route notifications: 210, En route responses: 13\n"
     ]
    }
   ],
   "source": [
    "users = deepcopy(raw_data['_User'])\n",
    "users = users[users['vendorId'] != '']\n",
    "\n",
    "tasklocations = deepcopy(raw_data['TaskLocations'])\n",
    "enroutelocations = deepcopy(raw_data['EnRouteLocations'])\n",
    "\n",
    "atlocnotif = deepcopy(raw_data['AtLocationNotificationsSent'])\n",
    "atlocresp = deepcopy(raw_data['AtLocationNotificationResponses'])\n",
    "\n",
    "atdistnotif = deepcopy(raw_data['AtDistanceNotificationsSent'])\n",
    "atdistresp = deepcopy(raw_data['AtDistanceNotificationResponses'])\n",
    "\n",
    "enroutenotif = deepcopy(raw_data['EnRouteNotificationsSent'])\n",
    "enrouteresp = deepcopy(raw_data['EnRouteNotificationResponses'])\n",
    "\n",
    "foryou = deepcopy(raw_data['ForYouViewLog'])\n",
    "\n",
    "# location_updates = deepcopy(raw_data['LocationUpdates'])\n",
    "\n",
    "print('4X | User Count: {}'.format(len(users)))\n",
    "print('4X | At location notifications: {}, At location responses: {}'.format(len(atlocnotif), len(atlocresp)))\n",
    "print('4X | At distance notifications: {}, At distance responses: {}'.format(len(atdistnotif), len(atdistresp)))\n",
    "print('4X | En route notifications: {}, En route responses: {}'.format(len(enroutenotif), len(enrouteresp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4X | User Count: 18\n",
      "4X | At location notifications: 154, At location responses: 68\n",
      "4X | At distance notifications: 107, At distance responses: 67\n",
      "4X | En route notifications: 210, En route responses: 13\n"
     ]
    }
   ],
   "source": [
    "# exclude kapil and rob\n",
    "user_exclude_ids = [\n",
    "    '20E1994C-9296-466F-B8FB-B5804C1C2121', # kapil\n",
    "    '88991A9A-2302-4359-B8AE-4E2F2505E6AE', # rob\n",
    "    '' # random blank id\n",
    "]\n",
    "\n",
    "users = users[~users['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "atlocnotif = atlocnotif[~atlocnotif['vendorId'].isin(user_exclude_ids)]\n",
    "atlocresp = atlocresp[~atlocresp['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "atdistnotif = atdistnotif[~atdistnotif['vendorId'].isin(user_exclude_ids)]\n",
    "atdistresp = atdistresp[~atdistresp['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "enroutenotif = enroutenotif[~enroutenotif['vendorId'].isin(user_exclude_ids)]\n",
    "enrouteresp = enrouteresp[~enrouteresp['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "foryou = foryou[~foryou['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "# location_updates = location_updates[~location_updates['vendorId'].isin(user_exclude_ids)]\n",
    "\n",
    "print('4X | User Count: {}'.format(len(users)))\n",
    "print('4X | At location notifications: {}, At location responses: {}'.format(len(atlocnotif), len(atlocresp)))\n",
    "print('4X | At distance notifications: {}, At distance responses: {}'.format(len(atdistnotif), len(atdistresp)))\n",
    "print('4X | En route notifications: {}, En route responses: {}'.format(len(enroutenotif), len(enrouteresp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge notifications and responses for both at-location and at-distance notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged data frame with all AtLocation data\n",
    "atloc = get_merged_at_location(deepcopy(tasklocations), deepcopy(atlocnotif),deepcopy(atlocresp))\n",
    "\n",
    "# add date and week\n",
    "atloc['date'] = pd.to_datetime(atloc['notificationTimestamp'] + atloc['gmtOffset'], unit='s').dt.date\n",
    "atloc['week'] = atloc['date'].apply(lambda x: 'Week 1' if x < mid_time_date.date() else 'Week 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged data frame with all AtDistance data\n",
    "atdist = get_merged_at_distance(deepcopy(tasklocations),\n",
    "                                   deepcopy(atdistnotif),\n",
    "                                   deepcopy(atdistresp))\n",
    "atdist = atdist[atdist['infoIncluded'] == True] # 4X Only: remove cases without info\n",
    "\n",
    "# add date and week\n",
    "atdist['date'] = pd.to_datetime(atdist['notificationTimestamp'] + atdist['gmtOffset'], unit='s').dt.date\n",
    "atdist['week'] = atdist['date'].apply(lambda x: 'Week 1' if x < mid_time_date.date() else 'Week 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For at-distance, include whether user went to location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eXpand providing more data at location overall\n",
    "atdist_didgo_overall = merge_atdist_atloc(deepcopy(atdist), deepcopy(atloc))\n",
    "atdist_didgo_overall['time_diff_seconds'] = (atdist_didgo_overall['atloc_notificationTimestamp'].fillna(0) - atdist_didgo_overall['atdist_responseTimestamp']).astype(int)\n",
    "atdist_didgo_overall['time_diff_minutes'] = atdist_didgo_overall['time_diff_seconds'] / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Valid Response</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         remappedResponses  count\n",
       "0  \"I don't know\" Response      4\n",
       "1               Did Not Go     79\n",
       "2   Dismissed Notification      1\n",
       "3      Missed Notification      7\n",
       "4           Valid Response     16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atdist_didgo_overall.groupby(['remappedResponses'])['remappedResponses'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emaResponse</th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>No. This info isn't useful to me.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          emaResponse  \\\n",
       "0                              Dismissed Notification   \n",
       "1                                 Missed Notification   \n",
       "2                                 Missed Notification   \n",
       "3                                 Missed Notification   \n",
       "4                                 Missed Notification   \n",
       "5                                 Missed Notification   \n",
       "6                                   No. Other reason.   \n",
       "7   No. This info is useful, but I can't go there ...   \n",
       "8   No. This info is useful, but I can't go there ...   \n",
       "9                   No. This info isn't useful to me.   \n",
       "10   Yes! This info is useful. I'm going to go there.   \n",
       "11   Yes! This info is useful. I'm going to go there.   \n",
       "12   Yes! This info is useful. I'm going to go there.   \n",
       "13   Yes! This info is useful. I'm going to go there.   \n",
       "14  Yes. This info is useful but I'm already going...   \n",
       "15  Yes. This info is useful but I'm already going...   \n",
       "\n",
       "          remappedResponses  count  \n",
       "0                Did Not Go      3  \n",
       "1   \"I don't know\" Response      3  \n",
       "2                Did Not Go     29  \n",
       "3    Dismissed Notification      1  \n",
       "4       Missed Notification      5  \n",
       "5            Valid Response      2  \n",
       "6                Did Not Go      5  \n",
       "7                Did Not Go     34  \n",
       "8            Valid Response      4  \n",
       "9                Did Not Go      4  \n",
       "10  \"I don't know\" Response      1  \n",
       "11               Did Not Go      3  \n",
       "12      Missed Notification      1  \n",
       "13           Valid Response     10  \n",
       "14               Did Not Go      1  \n",
       "15      Missed Notification      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atdist_didgo_overall.groupby(['emaResponse', 'remappedResponses'])['remappedResponses'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationType</th>\n",
       "      <th>emaResponse</th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffeeshop</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coffeeshop</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coffeeshop</td>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffeeshop</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffeeshop</td>\n",
       "      <td>No. This info isn't useful to me.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>freefood</td>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>freefood</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>freefood</td>\n",
       "      <td>No. This info isn't useful to me.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>freefood</td>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gym</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gym</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gym</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gym</td>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gym</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gym</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gym</td>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gym</td>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gym</td>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>workspace</td>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>workspace</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>workspace</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>workspace</td>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>workspace</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>workspace</td>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>workspace</td>\n",
       "      <td>No. This info isn't useful to me.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>workspace</td>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationType                                        emaResponse  \\\n",
       "0    coffeeshop                                Missed Notification   \n",
       "1    coffeeshop                                Missed Notification   \n",
       "2    coffeeshop                                  No. Other reason.   \n",
       "3    coffeeshop  No. This info is useful, but I can't go there ...   \n",
       "4    coffeeshop                  No. This info isn't useful to me.   \n",
       "5      freefood                                Missed Notification   \n",
       "6      freefood                                Missed Notification   \n",
       "7      freefood                                Missed Notification   \n",
       "8      freefood                                Missed Notification   \n",
       "9      freefood                                  No. Other reason.   \n",
       "10     freefood  No. This info is useful, but I can't go there ...   \n",
       "11     freefood                  No. This info isn't useful to me.   \n",
       "12     freefood   Yes! This info is useful. I'm going to go there.   \n",
       "13     freefood   Yes! This info is useful. I'm going to go there.   \n",
       "14     freefood   Yes! This info is useful. I'm going to go there.   \n",
       "15          gym                                Missed Notification   \n",
       "16          gym                                Missed Notification   \n",
       "17          gym                                Missed Notification   \n",
       "18          gym                                  No. Other reason.   \n",
       "19          gym  No. This info is useful, but I can't go there ...   \n",
       "20          gym  No. This info is useful, but I can't go there ...   \n",
       "21          gym   Yes! This info is useful. I'm going to go there.   \n",
       "22          gym  Yes. This info is useful but I'm already going...   \n",
       "23          gym  Yes. This info is useful but I'm already going...   \n",
       "24    workspace                             Dismissed Notification   \n",
       "25    workspace                                Missed Notification   \n",
       "26    workspace                                Missed Notification   \n",
       "27    workspace                                  No. Other reason.   \n",
       "28    workspace  No. This info is useful, but I can't go there ...   \n",
       "29    workspace  No. This info is useful, but I can't go there ...   \n",
       "30    workspace                  No. This info isn't useful to me.   \n",
       "31    workspace   Yes! This info is useful. I'm going to go there.   \n",
       "\n",
       "          remappedResponses  count  \n",
       "0                Did Not Go      2  \n",
       "1            Valid Response      1  \n",
       "2                Did Not Go      1  \n",
       "3            Valid Response      2  \n",
       "4                Did Not Go      1  \n",
       "5   \"I don't know\" Response      1  \n",
       "6                Did Not Go     10  \n",
       "7    Dismissed Notification      1  \n",
       "8       Missed Notification      4  \n",
       "9                Did Not Go      2  \n",
       "10               Did Not Go     17  \n",
       "11               Did Not Go      1  \n",
       "12  \"I don't know\" Response      1  \n",
       "13               Did Not Go      2  \n",
       "14           Valid Response     10  \n",
       "15  \"I don't know\" Response      2  \n",
       "16               Did Not Go      7  \n",
       "17      Missed Notification      1  \n",
       "18               Did Not Go      1  \n",
       "19               Did Not Go      5  \n",
       "20           Valid Response      1  \n",
       "21      Missed Notification      1  \n",
       "22               Did Not Go      1  \n",
       "23      Missed Notification      1  \n",
       "24               Did Not Go      3  \n",
       "25               Did Not Go     10  \n",
       "26           Valid Response      1  \n",
       "27               Did Not Go      1  \n",
       "28               Did Not Go     12  \n",
       "29           Valid Response      1  \n",
       "30               Did Not Go      2  \n",
       "31               Did Not Go      1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atdist_didgo_overall.groupby(['locationType', 'emaResponse', 'remappedResponses'])['remappedResponses'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emaResponse</th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         emaResponse        remappedResponses  \\\n",
       "0   Yes! This info is useful. I'm going to go there.  \"I don't know\" Response   \n",
       "1   Yes! This info is useful. I'm going to go there.               Did Not Go   \n",
       "2   Yes! This info is useful. I'm going to go there.      Missed Notification   \n",
       "3   Yes! This info is useful. I'm going to go there.           Valid Response   \n",
       "4  Yes. This info is useful but I'm already going...               Did Not Go   \n",
       "5  Yes. This info is useful but I'm already going...      Missed Notification   \n",
       "\n",
       "   count  \n",
       "0      1  \n",
       "1      3  \n",
       "2      1  \n",
       "3     10  \n",
       "4      1  \n",
       "5      1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze only cases where user said yes\n",
    "atdist_didgo_yes = atdist_didgo_overall[atdist_didgo_overall['emaResponse'].isin([\"Yes! This info is useful. I'm going to go there.\", \"Yes. This info is useful but I'm already going there.\"])]\n",
    "atdist_didgo_yes.groupby(['emaResponse', 'remappedResponses'])['remappedResponses'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emaResponse</th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Did Not Go</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        emaResponse        remappedResponses  \\\n",
       "0  Yes! This info is useful. I'm going to go there.  \"I don't know\" Response   \n",
       "1  Yes! This info is useful. I'm going to go there.               Did Not Go   \n",
       "2  Yes! This info is useful. I'm going to go there.      Missed Notification   \n",
       "3  Yes! This info is useful. I'm going to go there.           Valid Response   \n",
       "\n",
       "   count  \n",
       "0      1  \n",
       "1      3  \n",
       "2      1  \n",
       "3     10  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze only cases where user said yes and went out of their way\n",
    "atdist_didgo_deviate = atdist_didgo_overall[atdist_didgo_overall['emaResponse'].isin([\"Yes! This info is useful. I'm going to go there.\"])]\n",
    "atdist_didgo_deviate.groupby(['emaResponse', 'remappedResponses'])['remappedResponses'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enRouteLocationId</th>\n",
       "      <th>vendorId</th>\n",
       "      <th>distanceToLocation</th>\n",
       "      <th>locationType</th>\n",
       "      <th>locationName</th>\n",
       "      <th>gmtOffset</th>\n",
       "      <th>notificationTimestamp</th>\n",
       "      <th>questionResponse</th>\n",
       "      <th>responseTimestamp</th>\n",
       "      <th>remappedResponses</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tnffEhyqJZ</td>\n",
       "      <td>D40E7F30-C6F1-45FD-80D2-50AEDBAAF4A3</td>\n",
       "      <td>11.810767</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Tech Rear Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535411299</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535411527</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>18</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ner3yTGWzJ</td>\n",
       "      <td>600C7D5C-EF49-4C95-B0D1-135DBBE0BE5C</td>\n",
       "      <td>28.085310</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>SPAC Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535570851</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535570879</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>14</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ner3yTGWzJ</td>\n",
       "      <td>25FF4B97-71BF-4BB3-A701-A6937D8DDF9A</td>\n",
       "      <td>18.876306</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>SPAC Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535581263</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535581234</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>17</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ner3yTGWzJ</td>\n",
       "      <td>25FF4B97-71BF-4BB3-A701-A6937D8DDF9A</td>\n",
       "      <td>15.745800</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>SPAC Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1536100158</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>-1</td>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>17</td>\n",
       "      <td>Week 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>5899504E-1461-48DE-9ACC-FB9F2A1FDAF8</td>\n",
       "      <td>28.218752</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535571977</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535571980</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-29</td>\n",
       "      <td>14</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>5899504E-1461-48DE-9ACC-FB9F2A1FDAF8</td>\n",
       "      <td>29.818691</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535660247</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535660266</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>15</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>E2DAC389-DD64-4AF8-934A-6D1EF7D68507</td>\n",
       "      <td>29.218763</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535664399</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535664361</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>16</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>5899504E-1461-48DE-9ACC-FB9F2A1FDAF8</td>\n",
       "      <td>29.802959</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1535743264</td>\n",
       "      <td>yes</td>\n",
       "      <td>1535743274</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>14</td>\n",
       "      <td>Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>5C2E50F3-D8D3-4D79-AF2C-B63360D11E5A</td>\n",
       "      <td>12.036184</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1536085030</td>\n",
       "      <td>yes</td>\n",
       "      <td>1536085024</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>13</td>\n",
       "      <td>Week 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bDFfkSV5PZ</td>\n",
       "      <td>5899504E-1461-48DE-9ACC-FB9F2A1FDAF8</td>\n",
       "      <td>27.717888</td>\n",
       "      <td>bikerack</td>\n",
       "      <td>Ford Bike Rack</td>\n",
       "      <td>-18000</td>\n",
       "      <td>1536085649</td>\n",
       "      <td>yes</td>\n",
       "      <td>1536085651</td>\n",
       "      <td>Valid Response</td>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>13</td>\n",
       "      <td>Week 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  enRouteLocationId                              vendorId  distanceToLocation  \\\n",
       "0        tnffEhyqJZ  D40E7F30-C6F1-45FD-80D2-50AEDBAAF4A3           11.810767   \n",
       "1        Ner3yTGWzJ  600C7D5C-EF49-4C95-B0D1-135DBBE0BE5C           28.085310   \n",
       "2        Ner3yTGWzJ  25FF4B97-71BF-4BB3-A701-A6937D8DDF9A           18.876306   \n",
       "3        Ner3yTGWzJ  25FF4B97-71BF-4BB3-A701-A6937D8DDF9A           15.745800   \n",
       "4        bDFfkSV5PZ  5899504E-1461-48DE-9ACC-FB9F2A1FDAF8           28.218752   \n",
       "5        bDFfkSV5PZ  5899504E-1461-48DE-9ACC-FB9F2A1FDAF8           29.818691   \n",
       "6        bDFfkSV5PZ  E2DAC389-DD64-4AF8-934A-6D1EF7D68507           29.218763   \n",
       "7        bDFfkSV5PZ  5899504E-1461-48DE-9ACC-FB9F2A1FDAF8           29.802959   \n",
       "8        bDFfkSV5PZ  5C2E50F3-D8D3-4D79-AF2C-B63360D11E5A           12.036184   \n",
       "9        bDFfkSV5PZ  5899504E-1461-48DE-9ACC-FB9F2A1FDAF8           27.717888   \n",
       "\n",
       "  locationType         locationName  gmtOffset  notificationTimestamp  \\\n",
       "0     bikerack  Tech Rear Bike Rack     -18000             1535411299   \n",
       "1     bikerack       SPAC Bike Rack     -18000             1535570851   \n",
       "2     bikerack       SPAC Bike Rack     -18000             1535581263   \n",
       "3     bikerack       SPAC Bike Rack     -18000             1536100158   \n",
       "4     bikerack       Ford Bike Rack     -18000             1535571977   \n",
       "5     bikerack       Ford Bike Rack     -18000             1535660247   \n",
       "6     bikerack       Ford Bike Rack     -18000             1535664399   \n",
       "7     bikerack       Ford Bike Rack     -18000             1535743264   \n",
       "8     bikerack       Ford Bike Rack     -18000             1536085030   \n",
       "9     bikerack       Ford Bike Rack     -18000             1536085649   \n",
       "\n",
       "      questionResponse  responseTimestamp    remappedResponses        date  \\\n",
       "0                  yes         1535411527       Valid Response  2018-08-27   \n",
       "1                  yes         1535570879       Valid Response  2018-08-29   \n",
       "2                  yes         1535581234       Valid Response  2018-08-29   \n",
       "3  Missed Notification                 -1  Missed Notification  2018-09-04   \n",
       "4                  yes         1535571980       Valid Response  2018-08-29   \n",
       "5                  yes         1535660266       Valid Response  2018-08-30   \n",
       "6                  yes         1535664361       Valid Response  2018-08-30   \n",
       "7                  yes         1535743274       Valid Response  2018-08-31   \n",
       "8                  yes         1536085024       Valid Response  2018-09-04   \n",
       "9                  yes         1536085651       Valid Response  2018-09-04   \n",
       "\n",
       "   hour    week  \n",
       "0    18  Week 1  \n",
       "1    14  Week 1  \n",
       "2    17  Week 1  \n",
       "3    17  Week 2  \n",
       "4    14  Week 1  \n",
       "5    15  Week 1  \n",
       "6    16  Week 1  \n",
       "7    14  Week 1  \n",
       "8    13  Week 2  \n",
       "9    13  Week 2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged data from with all EnRoute data\n",
    "enroute = get_merged_en_route(deepcopy(enroutelocations), deepcopy(enroutenotif), deepcopy(enrouteresp))\n",
    "\n",
    "enroute['date'] = pd.to_datetime(enroute['notificationTimestamp'] + enroute['gmtOffset'], unit='s').dt.date\n",
    "enroute['hour'] = pd.to_datetime(enroute['notificationTimestamp'] + enroute['gmtOffset'], unit='s').dt.hour\n",
    "enroute['week'] = enroute['date'].apply(lambda x: 'Week 1' if x < mid_time_date.date() else 'Week 2')\n",
    "enroute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "foryou['date'] = pd.to_datetime(foryou['timestamp'] + foryou['gmtOffset'], unit='s').dt.date\n",
    "foryou['week'] = foryou['date'].apply(lambda x: 'Week 1' if x < mid_time_date.date() else 'Week 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Study Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from Google Sheets and merge with LES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_pre_study = [\n",
    "    'timestamp',\n",
    "    'name',\n",
    "    'email_address',\n",
    "    'gender',\n",
    "    'age',\n",
    "    'iphone_type',\n",
    "    'has_apple_watch',\n",
    "    'student_type',\n",
    "    'summer_task',\n",
    "    'campus_buildings',\n",
    "    'summer_times',\n",
    "    'study_duration',\n",
    "    'info_coffeeshop',\n",
    "    'info_gyms',\n",
    "    'info_workspace',\n",
    "    'info_freefood',\n",
    "    'info_other',\n",
    "    'info_followup'\n",
    "]\n",
    "pre_study_url = 'https://docs.google.com/spreadsheets/d/1_v7cxIy9jfOIAt_f917YT2Xx6K6o100zS-0Qtsosrr4/edit#gid=1619869885'\n",
    "pre_study_data = load_google_sheet_data(pre_study_url, new_col_names=cols_pre_study)\n",
    "pre_study_data.drop(['timestamp', 'study_duration', 'info_coffeeshop', 'info_gyms', 'info_workspace',\n",
    "                     'info_freefood', 'info_other', 'info_followup'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge users and pre-study survey\n",
    "users['full_name'] = users['firstName'] + ' ' + users['lastName']\n",
    "user_demographics = users[['vendorId', 'full_name']].merge(pre_study_data, left_on='full_name', right_on='name', how='left')\n",
    "user_demographics.drop(['full_name', 'name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean     23.933333\n",
       "std       3.692979\n",
       "min      19.000000\n",
       "25%      21.500000\n",
       "50%      23.000000\n",
       "75%      26.000000\n",
       "max      31.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_demographics['age'] = user_demographics['age'].astype(int)\n",
    "user_demographics[user_demographics['age'] > 0]['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              gender  count\n",
       "0             Female      8\n",
       "1               Male      9\n",
       "2  Prefer not to say      1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_demographics.groupby('gender')['gender'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undergraduate</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>postdoc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    student_type  count\n",
       "0       Graduate     12\n",
       "1  Undergraduate      5\n",
       "2        postdoc      1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_demographics.groupby('student_type')['student_type'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summer Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summer_task</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Conducting research as an undergraduate or gra...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Conducting research as an undergraduate or gra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Working at an on-campus job</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         summer_task  count\n",
       "0  Conducting research as an undergraduate or gra...     14\n",
       "1  Conducting research as an undergraduate or gra...      2\n",
       "2                        Working at an on-campus job      2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_demographics.groupby('summer_task')['summer_task'].count().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate Aggregations\n",
    "This section of the notebook is used to create any intermediate tables that will be used later on to create tables, graphs, and conduct more complex analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_prop_byloc(data, location_col, response_col):\n",
    "    \"\"\"\n",
    "    Computes and returns a groupby DataFrame with counts and proportions of responses, by location type.\n",
    "    \n",
    "    Input:\n",
    "        data (DataFrame): must include columns for location_col and response_col to aggregate on.\n",
    "        location_col (string): column containing location to aggregate on (e.g. locationType, locationName)\n",
    "        response_col (string): column containing response to aggregate (e.g. remappedResponses, emaResponse)\n",
    "    \n",
    "    Output:\n",
    "        (groupby DataFrame): aggregated data, by location\n",
    "    \"\"\"\n",
    "    count_byloc = data.groupby([location_col, response_col]).apply(lambda x: pd.Series({'count': x[response_col].count()},\n",
    "                                                                                       index=['count']))\n",
    "    prop_byloc = count_byloc.groupby(level=0, as_index=False).apply(lambda x: 100 * x / float(x.sum())).add_suffix('_proportion')\n",
    "\n",
    "    # combine count and proportion\n",
    "    combined_byloc = pd.concat([count_byloc, prop_byloc], axis=1)\n",
    "    \n",
    "    return combined_byloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_count_prop_overall(data, response_col):\n",
    "    \"\"\"\n",
    "    Computes and returns a DataFrame with counts and proportions of responses.\n",
    "    \n",
    "    Input:\n",
    "        data (DataFrame): must include column for response_col to aggregate on\n",
    "        response_col (string): column containing response to aggregate (e.g. remappedResponses, emaResponse)\n",
    "    \n",
    "    Output:\n",
    "        (DataFrame): aggregated data\n",
    "    \"\"\"\n",
    "    combined_overall = data.groupby([response_col])[response_col].count().reset_index(name='count')\n",
    "    combined_overall['percentage'] = 100.0 * combined_overall['count'] / sum(combined_overall['count'])\n",
    "    combined_overall.loc[len(combined_overall)] = ['Total', sum(combined_overall['count']), 100.0]\n",
    "    \n",
    "    return combined_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bytime_counts_overall(data, date_col, response_col):\n",
    "    \"\"\"\n",
    "    Computes and returns a DataFrame with counts of responses.\n",
    "    \n",
    "    Input:\n",
    "        data (DataFrame): must include column for response_col to aggregate on\n",
    "        date_col (string): column containing date/time to aggregate on\n",
    "        response_col (string): column containing response to aggregate (e.g. remappedResponses, emaResponse)\n",
    "    \n",
    "    Output:\n",
    "        (DataFrame): aggregated data\n",
    "    \"\"\"\n",
    "    combined_overall = data.groupby([date_col, response_col])[response_col].count().reset_index(name='count')\n",
    "    \n",
    "    return combined_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bytime_prop_overall(data, date_col, response_col):\n",
    "    \"\"\"\n",
    "    Computes and returns a DataFrame with counts and proportions of responses.\n",
    "    \n",
    "    Input:\n",
    "        data (DataFrame): must include column for response_col to aggregate on\n",
    "        date_col (string): column containing date/time to aggregate on\n",
    "        response_col (string): column containing response to aggregate (e.g. remappedResponses, emaResponse)\n",
    "    \n",
    "    Output:\n",
    "        (DataFrame): aggregated data\n",
    "    \"\"\"\n",
    "    combined_overall = data.groupby([date_col, response_col])[response_col].count()\n",
    "    combined_overall = combined_overall.groupby(level=0).apply(lambda x: 100 * x / float(x.sum())).reset_index(name='percentage')\n",
    "    \n",
    "    return combined_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_count_prop_byuser(data, users, user_col, response_col, valid_responses):\n",
    "    \"\"\"\n",
    "    Computes and returns a groupby DataFrame with counts and proportions of valid responses, by user.\n",
    "    \n",
    "    Input:\n",
    "        data (DataFrame): must include columns for user_col and response_col to aggregate on.\n",
    "        users (DataFrame): users to include for no responses\n",
    "        user_col (string): column containing users to aggregate on (e.g. vendorId)\n",
    "        response_col (string): column containing response to aggregate (e.g. remappedResponses, emaResponse)\n",
    "        valid_responses (list of strings): list of valid responses to include in final output\n",
    "    \n",
    "    Output:\n",
    "        (groupby DataFrame): aggregated data when valid response exists, by user\n",
    "    \"\"\"\n",
    "    count_byuser = data.groupby([user_col, response_col]).apply(lambda x: pd.Series({'count': x[response_col].count()},\n",
    "                                                                                       index=['count']))\n",
    "    prop_byuser = count_byuser.groupby(level=0, as_index=False).apply(lambda x: 100 * x / float(x.sum())).add_suffix('_proportion')\n",
    "\n",
    "    # combine count and proportion\n",
    "    combined_byloc = pd.concat([count_byuser, prop_byuser], axis=1).reset_index()\n",
    "    \n",
    "    # isolate only valid responses and return\n",
    "    combined_byloc = combined_byloc[combined_byloc[response_col].isin(valid_responses)].reset_index(drop=True)\n",
    "    \n",
    "    # include all people in dataframe\n",
    "    combined_byloc = combined_byloc.merge(users[['objectId', 'vendorId']], how='right')\n",
    "    del combined_byloc['objectId']\n",
    "    \n",
    "    # fill blanks\n",
    "    combined_byloc.fillna(value={\n",
    "        response_col: 'No Responses',\n",
    "        'count': 0,\n",
    "        'count_proportion': 0.0\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return combined_byloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXplore Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_count_prop_byloc = compute_count_prop_byloc(atloc, 'locationType', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_count_prop_overall = compute_count_prop_overall(atloc, 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique number of users notified: 14\n"
     ]
    }
   ],
   "source": [
    "print('Unique number of users notified: {}'.format(len(atloc['vendorId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_valid_responses = ['Valid Response']\n",
    "atloc_valid_count_prop_byuser = compute_valid_count_prop_byuser(atloc, users, 'vendorId', 'remappedResponses',\n",
    "                                                                   atloc_valid_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_byday_prop = compute_bytime_prop_overall(atloc, 'date', 'remappedResponses')\n",
    "atloc_byweek_prop = compute_bytime_prop_overall(atloc, 'week', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_byday_count = compute_bytime_counts_overall(atloc, 'date', 'remappedResponses')\n",
    "atloc_byweek_count = compute_bytime_counts_overall(atloc, 'week', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "foryou_byday_count = compute_bytime_counts_overall(foryou, 'date', 'logString')\n",
    "foryou_byday_count['condition'] = '4X'\n",
    "\n",
    "foryou_byweek_count = compute_bytime_counts_overall(foryou, 'week', 'logString')\n",
    "foryou_byweek_count['condition'] = '4X'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXpand Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "atdist_count_prop_byloc = compute_count_prop_byloc(atdist, 'locationType', 'emaResponse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "atdist_count_prop_overall = compute_count_prop_overall(atdist, 'emaResponse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique number of users notified: 17\n"
     ]
    }
   ],
   "source": [
    "print('Unique number of users notified: {}'.format(len(atdist['vendorId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "atdist_valid_responses = ['Yes! This info is useful. I\\'m going to go there.']\n",
    "atdist_valid_count_prop_byuser = compute_valid_count_prop_byuser(atdist, users, 'vendorId', 'emaResponse',\n",
    "                                                                    atdist_valid_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "atdist_byday_prop = compute_bytime_prop_overall(atdist, 'date', 'emaResponse')\n",
    "atdist_byweek_prop = compute_bytime_prop_overall(atdist, 'week', 'emaResponse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "atdist_byday_count = compute_bytime_counts_overall(atdist, 'date', 'emaResponse')\n",
    "atdist_byweek_count = compute_bytime_counts_overall(atdist, 'week', 'emaResponse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eXploit Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroute_count_prop_byloc = compute_count_prop_byloc(enroute, 'locationType', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroute_count_prop_overall = compute_count_prop_overall(enroute, 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique number of users notified: 6\n"
     ]
    }
   ],
   "source": [
    "print('Unique number of users notified: {}'.format(len(enroute['vendorId'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroute_valid_responses = ['Valid Response']\n",
    "enroute_valid_count_prop_byuser = compute_valid_count_prop_byuser(enroute, users, 'vendorId', 'remappedResponses',\n",
    "                                                                     enroute_valid_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroute_byday_prop = compute_bytime_prop_overall(enroute, 'date', 'remappedResponses')\n",
    "enroute_byweek_prop = compute_bytime_prop_overall(enroute, 'week', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroute_byday_count = compute_bytime_counts_overall(enroute, 'date', 'remappedResponses')\n",
    "enroute_byweek_count = compute_bytime_counts_overall(enroute, 'week', 'remappedResponses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Tables\n",
    "This section creates the tables that we used for the CHI'18 version of the LES paper. They, for the most part, will be the final tables included in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_study_table(count_prop_df, location_col, response_col, column_dict, response_list):\n",
    "    \"\"\"\n",
    "    Creates the equivalent table found in the paper using a count_prop table.\n",
    "    \n",
    "    Input: \n",
    "        count_prop_df (DataFrame): DataFrame with locationType, remappedResponses, count, and count_proportion\n",
    "        location_col (str): column to get locations for columns (e.g. coffeeshops, freefood, etc.)\n",
    "        response_col (str): column to get responses for rows (e.g. emaResponses, remappedResponses)\n",
    "        column_dict (dict): columns to include (i.e. locationTypes) in table with label remaps\n",
    "        response_list (list of str): responses to copy over to new table (e.g. Missed Notif)\n",
    "    \"\"\"\n",
    "    # add additional columns to beginning of table\n",
    "    columns = ['Response Type', 'Overall']\n",
    "    columns += column_dict.keys()\n",
    "    \n",
    "    # add total row\n",
    "    response_types = deepcopy(response_list)\n",
    "    response_types += ['Total']\n",
    "    \n",
    "    # create output DataFrame\n",
    "    output_dict = {'Response Type': response_types}\n",
    "    output_df = pd.DataFrame(output_dict)\n",
    "    \n",
    "    # populate each cell\n",
    "    for col in columns:\n",
    "        # ignore first response type column\n",
    "        if col == 'Response Type':\n",
    "            continue\n",
    "\n",
    "        # get counts for each row)\n",
    "        for row in response_types: \n",
    "            if row != 'Total':\n",
    "                if col == 'Overall':\n",
    "                    output_df.loc[response_types.index(row), col] = count_prop_df.loc[count_prop_df[response_col] == row, 'count'].sum()\n",
    "                else:\n",
    "                    output_df.loc[response_types.index(row), col] = count_prop_df.loc[(count_prop_df[location_col] == col) &\n",
    "                                                                                      (count_prop_df[response_col] == row), 'count'].sum()\n",
    "\n",
    "        # get total\n",
    "        output_df.loc[response_types.index('Total'), col] = output_df[0:-1][col].sum()\n",
    "\n",
    "        # create proportion and save\n",
    "        epsilon = 0.00000000001\n",
    "        col_proportions = (100 * output_df[col] / (float(output_df.loc[response_types.index('Total'), col]) + epsilon)).astype(np.double).round(2)\n",
    "        \n",
    "        # create labels for each\n",
    "        output_df[col] = col_proportions.astype(str) + '% (' + output_df[col].astype(np.int).astype(str) + ')'\n",
    "        \n",
    "    # reorder columns\n",
    "    output_df.columns = columns\n",
    "    \n",
    "    # remap column names\n",
    "    output_df.rename(columns=column_dict, inplace=True)\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_remapping = {'coffeeshop': 'Coffee Shops', 'freefood': 'Free Food', 'gym': 'Gyms', 'workspace': 'Workspaces'}\n",
    "atloc_response_list = ['Valid Response', '\"I don\\'t know\" Response',\n",
    "                        'Dismissed Notification', 'Missed Notification']\n",
    "atdist_info_response_list = ['Yes! This info is useful. I\\'m going to go there.',\n",
    "                            'Yes. This info is useful but I\\'m already going there.',\n",
    "                            'No. This info is useful, but I can\\'t go there now.',\n",
    "                            'No. This info isn\\'t useful to me.',\n",
    "                            'No. Other reason.',\n",
    "                            'Dismissed Notification',\n",
    "                            'Missed Notification']\n",
    "atdist_noinfo_response_list = ['Sure! I would be happy to go out of my way!',\n",
    "                               'Sure, but I was going to walk past it anyway.',\n",
    "                               'No. I don\\'t want to go out of my way there.',\n",
    "                               'No. Other reason.',\n",
    "                               'Dismissed Notification',\n",
    "                               'Missed Notification']\n",
    "atdist_all_response_list = list(set(atdist_info_response_list + atdist_noinfo_response_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Rates by Response Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXplore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response Type</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Coffee Shops</th>\n",
       "      <th>Free Food</th>\n",
       "      <th>Gyms</th>\n",
       "      <th>Workspaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valid Response</td>\n",
       "      <td>45.36% (44)</td>\n",
       "      <td>28.95% (11)</td>\n",
       "      <td>63.16% (12)</td>\n",
       "      <td>31.82% (7)</td>\n",
       "      <td>77.78% (14)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>20.62% (20)</td>\n",
       "      <td>18.42% (7)</td>\n",
       "      <td>10.53% (2)</td>\n",
       "      <td>50.0% (11)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>2.06% (2)</td>\n",
       "      <td>2.63% (1)</td>\n",
       "      <td>5.26% (1)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>31.96% (31)</td>\n",
       "      <td>50.0% (19)</td>\n",
       "      <td>21.05% (4)</td>\n",
       "      <td>18.18% (4)</td>\n",
       "      <td>22.22% (4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total</td>\n",
       "      <td>100.0% (97)</td>\n",
       "      <td>100.0% (38)</td>\n",
       "      <td>100.0% (19)</td>\n",
       "      <td>100.0% (22)</td>\n",
       "      <td>100.0% (18)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Response Type      Overall Coffee Shops    Free Food  \\\n",
       "0           Valid Response  45.36% (44)  28.95% (11)  63.16% (12)   \n",
       "1  \"I don't know\" Response  20.62% (20)   18.42% (7)   10.53% (2)   \n",
       "2   Dismissed Notification    2.06% (2)    2.63% (1)    5.26% (1)   \n",
       "3      Missed Notification  31.96% (31)   50.0% (19)   21.05% (4)   \n",
       "4                    Total  100.0% (97)  100.0% (38)  100.0% (19)   \n",
       "\n",
       "          Gyms   Workspaces  \n",
       "0   31.82% (7)  77.78% (14)  \n",
       "1   50.0% (11)     0.0% (0)  \n",
       "2     0.0% (0)     0.0% (0)  \n",
       "3   18.18% (4)   22.22% (4)  \n",
       "4  100.0% (22)  100.0% (18)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atloc_tabledata = atloc_count_prop_byloc.reset_index()\n",
    "create_study_table(atloc_tabledata, 'locationType', 'remappedResponses',\n",
    "                   location_remapping, atloc_response_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXpand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response Type</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Coffee Shops</th>\n",
       "      <th>Free Food</th>\n",
       "      <th>Gyms</th>\n",
       "      <th>Workspaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes! This info is useful. I'm going to go there.</td>\n",
       "      <td>14.02% (15)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>26.53% (13)</td>\n",
       "      <td>5.0% (1)</td>\n",
       "      <td>3.23% (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes. This info is useful but I'm already going...</td>\n",
       "      <td>1.87% (2)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>10.0% (2)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No. This info is useful, but I can't go there ...</td>\n",
       "      <td>35.51% (38)</td>\n",
       "      <td>28.57% (2)</td>\n",
       "      <td>34.69% (17)</td>\n",
       "      <td>30.0% (6)</td>\n",
       "      <td>41.94% (13)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No. This info isn't useful to me.</td>\n",
       "      <td>3.74% (4)</td>\n",
       "      <td>14.29% (1)</td>\n",
       "      <td>2.04% (1)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>6.45% (2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No. Other reason.</td>\n",
       "      <td>4.67% (5)</td>\n",
       "      <td>14.29% (1)</td>\n",
       "      <td>4.08% (2)</td>\n",
       "      <td>5.0% (1)</td>\n",
       "      <td>3.23% (1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>2.8% (3)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>9.68% (3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>37.38% (40)</td>\n",
       "      <td>42.86% (3)</td>\n",
       "      <td>32.65% (16)</td>\n",
       "      <td>50.0% (10)</td>\n",
       "      <td>35.48% (11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total</td>\n",
       "      <td>100.0% (107)</td>\n",
       "      <td>100.0% (7)</td>\n",
       "      <td>100.0% (49)</td>\n",
       "      <td>100.0% (20)</td>\n",
       "      <td>100.0% (31)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Response Type       Overall  \\\n",
       "0   Yes! This info is useful. I'm going to go there.   14.02% (15)   \n",
       "1  Yes. This info is useful but I'm already going...     1.87% (2)   \n",
       "2  No. This info is useful, but I can't go there ...   35.51% (38)   \n",
       "3                  No. This info isn't useful to me.     3.74% (4)   \n",
       "4                                  No. Other reason.     4.67% (5)   \n",
       "5                             Dismissed Notification      2.8% (3)   \n",
       "6                                Missed Notification   37.38% (40)   \n",
       "7                                              Total  100.0% (107)   \n",
       "\n",
       "  Coffee Shops    Free Food         Gyms   Workspaces  \n",
       "0     0.0% (0)  26.53% (13)     5.0% (1)    3.23% (1)  \n",
       "1     0.0% (0)     0.0% (0)    10.0% (2)     0.0% (0)  \n",
       "2   28.57% (2)  34.69% (17)    30.0% (6)  41.94% (13)  \n",
       "3   14.29% (1)    2.04% (1)     0.0% (0)    6.45% (2)  \n",
       "4   14.29% (1)    4.08% (2)     5.0% (1)    3.23% (1)  \n",
       "5     0.0% (0)     0.0% (0)     0.0% (0)    9.68% (3)  \n",
       "6   42.86% (3)  32.65% (16)   50.0% (10)  35.48% (11)  \n",
       "7   100.0% (7)  100.0% (49)  100.0% (20)  100.0% (31)  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atdist_info_tabledata = atdist_count_prop_byloc.reset_index()\n",
    "create_study_table(atdist_info_tabledata, 'locationType', 'emaResponse',\n",
    "                   location_remapping, atdist_info_response_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXploit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response Type</th>\n",
       "      <th>Overall</th>\n",
       "      <th>Bike Rack</th>\n",
       "      <th>Parking Lot Spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Valid Response</td>\n",
       "      <td>90.0% (9)</td>\n",
       "      <td>90.0% (9)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I don't know\" Response</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dismissed Notification</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Missed Notification</td>\n",
       "      <td>10.0% (1)</td>\n",
       "      <td>10.0% (1)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total</td>\n",
       "      <td>100.0% (10)</td>\n",
       "      <td>100.0% (10)</td>\n",
       "      <td>0.0% (0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Response Type      Overall    Bike Rack Parking Lot Spaces\n",
       "0           Valid Response    90.0% (9)    90.0% (9)           0.0% (0)\n",
       "1  \"I don't know\" Response     0.0% (0)     0.0% (0)           0.0% (0)\n",
       "2   Dismissed Notification     0.0% (0)     0.0% (0)           0.0% (0)\n",
       "3      Missed Notification    10.0% (1)    10.0% (1)           0.0% (0)\n",
       "4                    Total  100.0% (10)  100.0% (10)           0.0% (0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enroute_location_remapping = {'bikerack': 'Bike Rack', 'parkingspace': 'Parking Lot Spaces'}\n",
    "enroute_tabledata = enroute_count_prop_byloc.reset_index()\n",
    "create_study_table(enroute_tabledata, 'locationType', 'remappedResponses',\n",
    "                   enroute_location_remapping, atloc_response_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs\n",
    "This section creates some visualizations of the above data. Some will be used in the final paper, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Reported Disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_study_opp_loc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-f86ced54a795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m plot_melted_dfs = [\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mcreate_boxplot_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Opp at Location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_study_opp_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mcreate_boxplot_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4X'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_study_4x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcreate_boxplot_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Opp at Distance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_study_opp_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'post_study_opp_loc' is not defined"
     ]
    }
   ],
   "source": [
    "def create_boxplot_df(condition, df):\n",
    "    \"\"\"\n",
    "    Creates a simple melted DF with a condition column, and a column for each attribute (value, disruption, future use, etc) to be plotted.\n",
    "    \n",
    "    Inputs:\n",
    "        condition (string): name of condition\n",
    "        df (DataFrame): current data\n",
    "    \n",
    "    Returns:\n",
    "        (DataFrame): simplified DataFrame ready for concating and plotting\n",
    "    \"\"\"\n",
    "    return pd.DataFrame({'condition': condition, 'value': df['overall_value'], 'disruption': df['overall_disruption'], 'future use': df['future_use']}).melt(id_vars=['condition'])\n",
    "\n",
    "plot_melted_dfs = [\n",
    "    create_boxplot_df('Opp at Location', post_study_opp_loc),\n",
    "    create_boxplot_df('4X', post_study_4x),\n",
    "    create_boxplot_df('Opp at Distance', post_study_opp_dist)\n",
    "]\n",
    "disruption_plot_data = pd.concat(plot_melted_dfs)\n",
    "disruption_plot_data = disruption_plot_data[disruption_plot_data['value'] > 0] # dont include any responses that werent filled or were NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.boxplot(x='condition', y='value', hue='variable', data=disruption_plot_data,\n",
    "                 hue_order=['disruption', 'value', 'future use'])\n",
    "ax.set_title('Disruption, Value, and Likeliness to Use in Future')\n",
    "ax.set_xlabel('Study Conditions')\n",
    "ax.set_ylabel('Value on 5-Point Likert Scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_study_opp_loc['overall_disruption'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_study_4x['overall_disruption'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_study_opp_dist['overall_disruption'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Significance on Disruption and Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as special\n",
    "\n",
    "def FPvalue( *args):\n",
    "    \"\"\" Return F an p value\n",
    "\n",
    "    \"\"\"\n",
    "    df_btwn, df_within = __degree_of_freedom_( *args)\n",
    "\n",
    "    mss_btwn = __ss_between_( *args) / float( df_btwn)   \n",
    "    mss_within = __ss_within_( *args) / float( df_within)\n",
    "\n",
    "    F = mss_btwn / mss_within    \n",
    "    P = special.fdtrc( df_btwn, df_within, F)\n",
    "\n",
    "    return( F, P)\n",
    "\n",
    "def EffectSize( *args):\n",
    "    \"\"\" Return the eta squared as the effect size for ANOVA\n",
    "\n",
    "    \"\"\"    \n",
    "    return( float( __ss_between_( *args) / __ss_total_( *args)))\n",
    "\n",
    "def __concentrate_( *args):\n",
    "    \"\"\" Concentrate input list-like arrays\n",
    "\n",
    "    \"\"\"\n",
    "    v = list( map( np.asarray, args))\n",
    "    vec = np.hstack( np.concatenate( v))\n",
    "    return( vec)\n",
    "\n",
    "def __ss_total_( *args):\n",
    "    \"\"\" Return total of sum of square\n",
    "\n",
    "    \"\"\"\n",
    "    vec = __concentrate_( *args)\n",
    "    ss_total = sum( (vec - np.mean( vec)) **2)\n",
    "    return( ss_total)\n",
    "\n",
    "def __ss_between_( *args):\n",
    "    \"\"\" Return between-subject sum of squares\n",
    "\n",
    "    \"\"\"    \n",
    "    # grand mean\n",
    "    grand_mean = np.mean( __concentrate_( *args))\n",
    "\n",
    "    ss_btwn = 0\n",
    "    for a in args:\n",
    "        ss_btwn += ( len(a) * ( np.mean( a) - grand_mean) **2)\n",
    "\n",
    "    return( ss_btwn)\n",
    "\n",
    "def __ss_within_( *args):\n",
    "    \"\"\"Return within-subject sum of squares\n",
    "\n",
    "    \"\"\"\n",
    "    return( __ss_total_( *args) - __ss_between_( *args))\n",
    "\n",
    "def __degree_of_freedom_( *args):\n",
    "    \"\"\"Return degree of freedom\n",
    "\n",
    "       Output-\n",
    "              Between-subject dof, within-subject dof\n",
    "    \"\"\"   \n",
    "    args = list( map( np.asarray, args))\n",
    "    # number of groups minus 1\n",
    "    df_btwn = len( args) - 1\n",
    "\n",
    "    # total number of samples minus number of groups\n",
    "    df_within = len( __concentrate_( *args)) - df_btwn - 1\n",
    "\n",
    "    return( df_btwn, df_within)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data for ANOVA in R\n",
    "anova_data = pd.concat([\n",
    "    pd.DataFrame({'disruption': post_study_4x['overall_disruption'], 'condition': '4X'}),\n",
    "    pd.DataFrame({'disruption': post_study_opp_dist['overall_disruption'], 'condition': 'Opportunistic'}),\n",
    "    pd.DataFrame({'disruption': post_study_opp_loc['overall_disruption'], 'condition': 'Directed'})\n",
    "])\n",
    "\n",
    "anova_data.to_csv(path_or_buf='./analysis/anova_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, p = stats.f_oneway(post_study_4x['overall_disruption'],\n",
    "                      post_study_opp_dist['overall_disruption'],\n",
    "                      post_study_opp_loc['overall_disruption'])\n",
    "d = EffectSize(post_study_4x['overall_disruption'],\n",
    "               post_study_opp_dist['overall_disruption'],\n",
    "               post_study_opp_loc['overall_disruption'])\n",
    "\n",
    "df_btwn, df_within = __degree_of_freedom_(post_study_4x['overall_disruption'],\n",
    "                                          post_study_opp_dist['overall_disruption'],\n",
    "                                          post_study_opp_loc['overall_disruption'])\n",
    "\n",
    "anova_output_string = 'ANOVA on Disruption \\nF({}, {}) = {:1.3f}, p = {:1.3f}, Cohen\\'s d = {:1.3f}'\n",
    "print(anova_output_string.format(df_btwn, df_within, F, p, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, p = stats.f_oneway(post_study_4x['overall_value'],\n",
    "                      post_study_opp_dist['overall_value'],\n",
    "                      post_study_opp_loc['overall_value'])\n",
    "d = EffectSize(post_study_4x['overall_value'],\n",
    "               post_study_opp_dist['overall_value'],\n",
    "               post_study_opp_loc['overall_value'])\n",
    "\n",
    "print('ANOVA on Value \\nF: {:1.3f}, p: {:1.3f}, Cohen\\'s d: {:1.3f}'.format(F, p, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, p = stats.f_oneway(post_study_4x['future_use'],\n",
    "                      post_study_opp_dist['future_use'],\n",
    "                      post_study_opp_loc['future_use'])\n",
    "d = EffectSize(post_study_4x['future_use'],\n",
    "               post_study_opp_dist['future_use'],\n",
    "               post_study_opp_loc['future_use'])\n",
    "\n",
    "print('ANOVA on Future Use \\nF: {:1.3f}, p: {:1.3f}, Cohen\\'s d: {:1.3f}'.format(F, p, d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data vs. Pickup Rate vs. Disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_acceptance_rate_data = pd.DataFrame({\n",
    "#     'condition': [\n",
    "#         '4X',\n",
    "#         'Opp at Distance',\n",
    "#         'Opp at Location',\n",
    "#         '4X',\n",
    "#         'Opp at Distance',\n",
    "#         'Opp at Distance',\n",
    "        \n",
    "#     ],\n",
    "#     'variable': [\n",
    "#         'Valid Response Rate \\n At Location',\n",
    "#         'Valid Response Rate \\n At Location',\n",
    "#         'Valid Response Rate \\n At Location',\n",
    "#         'Task Acceptance Rate (with Info) \\n 300m Away',\n",
    "#         'Task Acceptance Rate (with Info) \\n 300m Away',\n",
    "#         'Task Acceptance Rate (without Info) \\n 300m Away',\n",
    "#     ],\n",
    "#     'value': [\n",
    "#         float(atloc_4x_count_prop_overall[atloc_4x_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "#         float(atloc_opp_dist_count_prop_overall[atloc_opp_dist_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "#         float(atloc_opp_loc_count_prop_overall[atloc_opp_loc_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "#         float(atdist_4x_count_prop_overall[atdist_4x_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "#         float(atdist_opp_dist_info_count_prop_overall[atdist_opp_dist_info_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "#         float(atdist_opp_dist_noinfo_count_prop_overall[atdist_opp_dist_noinfo_count_prop_overall['emaResponse'] == 'Sure! I would be happy to go out of my way!']['percentage']),\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "atdist_taskaccepted = [\n",
    "    'Yes! This info is useful, I\\'m going now.',\n",
    "    'Sure! I would be happy to go out of my way!'\n",
    "]\n",
    "\n",
    "task_acceptance_rate_data = pd.DataFrame({\n",
    "    'condition': [\n",
    "        '4X',\n",
    "        'Opp at Distance',\n",
    "        'Opp at Location',\n",
    "        '4X',\n",
    "        'Opp at Distance',\n",
    "    ],\n",
    "    'variable': [\n",
    "        'Valid Response Rate \\n At Location',\n",
    "        'Valid Response Rate \\n At Location',\n",
    "        'Valid Response Rate \\n At Location',\n",
    "        'Task Acceptance Rate \\n 300m Away',\n",
    "        'Task Acceptance Rate \\n 300m Away',\n",
    "    ],\n",
    "    'value': [\n",
    "        float(atloc_4x_count_prop_overall[atloc_4x_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "        float(atloc_opp_dist_count_prop_overall[atloc_opp_dist_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "        float(atloc_opp_loc_count_prop_overall[atloc_opp_loc_count_prop_overall['remappedResponses'] == 'Valid Response']['percentage']),\n",
    "        float(atdist_4x_count_prop_overall[atdist_4x_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "        float(atdist_opp_dist_all_count_prop_overall[atdist_opp_dist_all_count_prop_overall['emaResponse'].isin(atdist_taskaccepted)]['percentage'].sum())\n",
    "    ]\n",
    "})\n",
    "\n",
    "task_acceptance_rate_atdist_data = pd.DataFrame({\n",
    "    'condition': [\n",
    "        '4X',\n",
    "        'Opp at Distance',\n",
    "        'Opp at Distance'\n",
    "    ],\n",
    "    'variable': [\n",
    "        'Task Acceptance Rate (with Info) \\n 300m Away',\n",
    "        'Task Acceptance Rate (with Info) \\n 300m Away',\n",
    "        'Task Acceptance Rate (without Info) \\n 300m Away',\n",
    "    ],\n",
    "    'value': [\n",
    "        float(atdist_4x_count_prop_overall[atdist_4x_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "        float(atdist_opp_dist_info_count_prop_overall[atdist_opp_dist_info_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "        float(atdist_opp_dist_noinfo_count_prop_overall[atdist_opp_dist_noinfo_count_prop_overall['emaResponse'] == 'Sure! I would be happy to go out of my way!']['percentage']),\n",
    "    ]\n",
    "})\n",
    "\n",
    "overall_task_acceptance_rate_atdist_data = pd.DataFrame({\n",
    "    'condition': [\n",
    "        '4X',\n",
    "        'Opp at Distance'\n",
    "    ],\n",
    "    'variable': [\n",
    "        'Task Acceptance Rate',\n",
    "        'Task Acceptance Rate'\n",
    "    ],\n",
    "    'value': [\n",
    "        float(atdist_4x_count_prop_overall[atdist_4x_count_prop_overall['emaResponse'] == 'Yes! This info is useful, I\\'m going now.']['percentage']),\n",
    "        float(atdist_opp_dist_all_count_prop_overall[atdist_opp_dist_all_count_prop_overall['emaResponse'].isin(atdist_taskaccepted)]['percentage'].sum())\n",
    "    ]\n",
    "})\n",
    "\n",
    "people_notified_atdist_data = pd.DataFrame({\n",
    "    'condition': [\n",
    "        '4X',\n",
    "        'Opp at Distance'\n",
    "    ],\n",
    "    'variable': [\n",
    "        'Notification Count',\n",
    "        'Notification Count',\n",
    "    ],\n",
    "    'value': [\n",
    "        float(atdist_4x_count_prop_overall[atdist_4x_count_prop_overall['emaResponse'] == 'Total']['count']),\n",
    "        float(atdist_opp_dist_all_count_prop_overall[atdist_opp_dist_all_count_prop_overall['emaResponse'] == 'Total']['count'])\n",
    "    ]\n",
    "})\n",
    "\n",
    "disruption_value_data = pd.concat([\n",
    "    pd.DataFrame({'condition': '4X', 'variable': 'Disruption \\n 5-Point Likert Scale', 'value': post_study_4x['overall_disruption']}),\n",
    "    pd.DataFrame({'condition': 'Opp at Distance', 'variable': 'Disruption \\n 5-Point Likert Scale', 'value': post_study_opp_dist['overall_disruption']}),\n",
    "    pd.DataFrame({'condition': 'Opp at Location', 'variable': 'Disruption \\n 5-Point Likert Scale', 'value': post_study_opp_loc['overall_disruption']}),\n",
    "    pd.DataFrame({'condition': '4X', 'variable': 'Value \\n 5-Point Likert Scale', 'value': post_study_4x['overall_value']}),\n",
    "    pd.DataFrame({'condition': 'Opp at Distance', 'variable': 'Value \\n 5-Point Likert Scale', 'value': post_study_opp_dist['overall_value']}),\n",
    "    pd.DataFrame({'condition': 'Opp at Location', 'variable': 'Value \\n 5-Point Likert Scale', 'value': post_study_opp_loc['overall_value']})\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(15, 8))\n",
    "ax = sns.barplot(x='variable', y='value', hue='condition', data=task_acceptance_rate_data,\n",
    "                 hue_order=['Opp at Location', '4X', 'Opp at Distance'])\n",
    "ax.set_title('Response Rate by Condition and Distance')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 5))\n",
    "ax.set_yticklabels(['{}%'.format(x) for x in range(0, 105, 5)])\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if math.isnan(height):\n",
    "        height = 0\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '', ha=\"center\") \n",
    "    else:\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(15, 8))\n",
    "ax = sns.barplot(x='variable', y='value', hue='condition', data=task_acceptance_rate_atdist_data,\n",
    "                 hue_order=['Opp at Location', '4X', 'Opp at Distance'])\n",
    "ax.set_title('Task Acceptance Rate At Distance With/Without Info')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Percentage (out of 100)')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 5))\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if math.isnan(height):\n",
    "        height = 0\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '', ha=\"center\") \n",
    "    else:\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_notified_atdist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.barplot(x='variable', y='value', hue='condition', data=people_notified_atdist_data,\n",
    "            hue_order=['Opp at Location', '4X', 'Opp at Distance'])\n",
    "ax.set_title('Notification Count At Distance With/Without Info')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Percentage (out of 100)')\n",
    "ax.set_ylim(0, 1000)\n",
    "ax.set_yticks(range(0, 1001, 50))\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if math.isnan(height):\n",
    "        height = 0\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '', ha=\"center\") \n",
    "    else:\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.5, '{:1.0f}'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_notified_atdist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.barplot(x='variable', y='value', hue='condition', data=disruption_value_data,\n",
    "                 hue_order=['Opp at Location', '4X', 'Opp at Distance'])\n",
    "ax.set_title('Self-Reported Disruption and Value')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('Average Rating')\n",
    "ax.set_ylim(0, 5)\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2, height + 0.4, '{:1.2f}'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info vs No Info Disruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_noinfo_plot_melted_dfs = [\n",
    "    pd.DataFrame({'condition': 'Opp at Location', 'at location': post_study_opp_loc['explore_disruption']}).melt(id_vars=['condition']),\n",
    "    pd.DataFrame({'condition': '4X', 'at location': post_study_4x['explore_disruption'], 'info included': post_study_4x['expand_info_disruption']}).melt(id_vars=['condition']),\n",
    "    pd.DataFrame({'condition': 'Opp at Distance', 'at location': post_study_opp_dist['explore_disruption'], 'no info included': post_study_opp_dist['expand_noinfo_disruption'], 'info included': post_study_opp_dist['expand_info_disruption']}).melt(id_vars=['condition'])\n",
    "]\n",
    "info_disruption_plot_data = pd.concat(info_noinfo_plot_melted_dfs)\n",
    "info_disruption_plot_data = info_disruption_plot_data[info_disruption_plot_data['value'] > 0] # dont include any responses that werent filled or were NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(12, 8))\n",
    "ax = sns.boxplot(x='condition', y='value', hue='variable', data=info_disruption_plot_data,\n",
    "                 hue_order=['at location', 'info included', 'no info included'])\n",
    "ax.set_title('Notification Disruptiveness by Notification Type')\n",
    "ax.set_xlabel('Study Condition')\n",
    "ax.set_ylabel('Value on 5-Point Likert Scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_noinfo_count_plot_melted_dfs = [\n",
    "    pd.DataFrame({'condition': '4X', 'info included': post_study_4x['expand_info_disruption'], 'info included count': post_study_4x['expand_info_number_notif']}).melt(id_vars=['condition']),\n",
    "    pd.DataFrame({'condition': 'Opp at Distance', 'no info included': post_study_opp_dist['expand_noinfo_disruption'], 'no info included count': post_study_opp_dist['expand_noinfo_number_notif'],\n",
    "                  'info included': post_study_opp_dist['expand_info_disruption'], 'info included count': post_study_opp_dist['expand_info_number_notif']}).melt(id_vars=['condition'])\n",
    "]\n",
    "info_disruption_count_plot_data = pd.concat(info_noinfo_count_plot_melted_dfs)\n",
    "info_disruption_count_plot_data = info_disruption_count_plot_data[info_disruption_count_plot_data['value'] > 0] # dont include any responses that werent filled or were NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(15, 8))\n",
    "ax = sns.boxplot(x='condition', y='value', hue='variable', data=info_disruption_count_plot_data,\n",
    "                 hue_order=['info included', 'info included count', 'no info included', 'no info included count'])\n",
    "ax.set_title('Disruptiveness and Desired Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notification Rates over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.pointplot(x='date', y='percentage', hue='emaResponse',\n",
    "                   data=atdist_byday_prop)\n",
    "\n",
    "ax.set_ylabel('Percentage (out of 100)')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('4X: At Distance EMA Reponse Over Time')\n",
    "\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_yticks(range(0, 105, 5))\n",
    "loc, labels = plt.xticks()\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.pointplot(x='date', y='percentage', hue='remappedResponses',\n",
    "                   data=atloc_byday_prop)\n",
    "\n",
    "ax.set_ylabel('Percentage (out of 100)')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('4X: At Location Reponse Over Time')\n",
    "\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_yticks(range(0, 105, 5))\n",
    "loc, labels = plt.xticks()\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.barplot(x='week', y='percentage', hue='emaResponse',\n",
    "                   data=atdist_byweek_prop)\n",
    "ax.set_title('4X: At Distance Task EMA Response Over Time')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_yticks(range(0, 105, 5))\n",
    "\n",
    "loc, labels = plt.xticks()\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.4, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.barplot(x='week', y='percentage', hue='remappedResponses',\n",
    "                   data=atloc_byweek_prop)\n",
    "ax.set_title('4X: At Location Response Over Time')\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_yticks(range(0, 105, 5))\n",
    "\n",
    "loc, labels = plt.xticks()\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 0.4, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaffolding by Condition and Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of locations by number of contributions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "atloc_contrib_hist = atloc[atloc['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_contrib_hist = atloc_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_contrib_hist['total_count'] = atloc_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_contrib_hist['proportion'] = 100 * atloc_contrib_hist['total_count'] / sum(atloc_contrib_hist['total_count'])\n",
    "\n",
    "ax = sns.barplot(data=atloc_contrib_hist,\n",
    "                 x='count', y='proportion', color=sns.color_palette()[0])\n",
    "ax.set(xlabel='Contribution Number to Location',\n",
    "       ylabel='Percentage of Total Contributions')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 5))\n",
    "ax.set_title('4X')\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atloc_contrib_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For You Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foryou_byweek_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foryou_data = pd.concat([\n",
    "    foryou_byweek_count,\n",
    "])\n",
    "\n",
    "# histogram of locations by number of contributions\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax = sns.barplot(data=foryou_data, x='week', y='count', hue='condition',\n",
    "                hue_order=['4X'])\n",
    "ax.set(xlabel='', ylabel='Number of Views')\n",
    "ax.set_ylim(0, 210)\n",
    "ax.set_yticks(range(0, 211, 10))\n",
    "ax.set_title('For You Page Views by Condition')\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.0f}'.format(height), ha=\"center\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper Plots\n",
    "This code is used to generate the final plots that will be used in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Rate and Disruption\n",
    "Left: Response rate At Location and Task Acceptance Rate 300m from location. For 4X, 300m notifications were only sent when preferential data was available, while for Opp at Distance notifications were always sent.  We see that the task acceptance rate is lower for Opp at Distance compared to 4X, with all three conditions having roughly the same At Location response rate.\n",
    "\n",
    "Right: Self-reported disruption and value of LES. Opp at Distance has significantly higher disruption than either Opp at Location or 4X (F: 3.935, p: 0.023, Cohen's d: 0.087). From the self-reported value, each system is shown to be approximately equally valuable. However, further analysis of the qualitative data indicates that Opp at Location users did not feel they gained much value from the application and wished that it notified them when information was available, similar to 4X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap variable names\n",
    "graph_replacement_dict = {\n",
    "    'condition': {\n",
    "        'Opp at Distance': 'Directed',\n",
    "        'Opp at Location': 'Opportunistic'\n",
    "    }\n",
    "}\n",
    "task_acceptance_rate_data.replace(graph_replacement_dict, inplace=True)\n",
    "disruption_value_data.replace(graph_replacement_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(25, 8))\n",
    "\n",
    "# create acceptance rate plot\n",
    "sns.barplot(x='variable', y='value', hue='condition', data=task_acceptance_rate_data,\n",
    "            hue_order=['Opportunistic', '4X', 'Directed'], ax=ax1)\n",
    "ax1.set_title('Response Rate by Condition and Distance')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Percentage')\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.set_yticks(range(0, 101, 5))\n",
    "ax1.set_yticklabels(['{}%'.format(x) for x in range(0, 105, 5)])\n",
    "\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    if math.isnan(height):\n",
    "        height = 0\n",
    "        ax1.text(p.get_x() + p.get_width() / 2, height + 0.5, '', ha=\"center\") \n",
    "    else:\n",
    "        ax1.text(p.get_x() + p.get_width() / 2, height + 0.5, '{:1.2f}%'.format(height), ha=\"center\") \n",
    "        \n",
    "# create disruption plot\n",
    "sns.barplot(x='variable', y='value', hue='condition', data=disruption_value_data,\n",
    "            hue_order=['Opportunistic', '4X', 'Directed'], ax=ax2)\n",
    "ax2.set_title('Self-Reported Disruption and Value')\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Average Rating')\n",
    "ax2.set_ylim(0, 5)\n",
    "\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    ax2.text(p.get_x() + p.get_width() / 2, height + 0.4, '{:1.2f}'.format(height), ha=\"center\") \n",
    "    \n",
    "# export plot\n",
    "output_fig = ax2.get_figure()\n",
    "output_fig.savefig('./graphs/acceptance-disruption.png', dpi=300, transparent=True, bbox_inches='tight', pad_inches=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# create disruption plot\n",
    "sns.barplot(x='variable', y='value', hue='condition', data=disruption_value_data,\n",
    "            hue_order=['Opportunistic', '4X', 'Directed'], ax=ax)\n",
    "ax.set_title('Self-Reported Disruption and Value', fontsize=24)\n",
    "ax.set_xlabel('', fontsize=24)\n",
    "ax.set_ylabel('Average Rating', fontsize=24)\n",
    "ax.set_ylim(0, 5)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x() + p.get_width() / 2, height + 0.4, '{:1.2f}'.format(height), ha=\"center\", fontsize=20) \n",
    "    \n",
    "# export plot\n",
    "output_fig = ax.get_figure()\n",
    "output_fig.savefig('./graphs/disruption.png', dpi=300, transparent=True, bbox_inches='tight', pad_inches=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaffolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of locations by number of contributions\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=False, figsize=(21, 6))\n",
    "plt.subplots_adjust(top=0.85)\n",
    "        \n",
    "# opportunistic\n",
    "atloc_opp_loc_contrib_hist = atloc_opp_loc[atloc_opp_loc['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_opp_loc_contrib_hist = atloc_opp_loc_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_opp_loc_contrib_hist['total_count'] = atloc_opp_loc_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_opp_loc_contrib_hist['proportion'] = 100 * atloc_opp_loc_contrib_hist['total_count'] / sum(atloc_opp_loc_contrib_hist['total_count'])\n",
    "atloc_opp_loc_contrib_hist = pd.concat([atloc_opp_loc_contrib_hist, \n",
    "                                        pd.DataFrame({'count': [5], 'instances': [0], 'total_count': [0], 'proportion': [0.0]})])\n",
    "\n",
    "sns.barplot(data=atloc_opp_loc_contrib_hist,\n",
    "            x='count', y='proportion', color=sns.color_palette()[0], ax=ax1)\n",
    "ax1.set_xlabel('Contribution Number to Location', fontsize=18)\n",
    "ax1.set_ylabel('Percentage of Total Contributions', fontsize=18)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.set_yticks(range(0, 101, 10))\n",
    "ax1.set_title('Opportunistic Condition', fontsize=20)\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax1.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax1.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\")\n",
    "        \n",
    "# 4X\n",
    "atloc_4x_contrib_hist = atloc_4x[atloc_4x['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_4x_contrib_hist = atloc_4x_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_4x_contrib_hist['total_count'] = atloc_4x_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_4x_contrib_hist['proportion'] = 100 * atloc_4x_contrib_hist['total_count'] / sum(atloc_4x_contrib_hist['total_count'])\n",
    "atloc_4x_contrib_hist = pd.concat([atloc_4x_contrib_hist, \n",
    "                                   pd.DataFrame({'count': [5], 'instances': [0], 'total_count': [0], 'proportion': [0.0]})])\n",
    "\n",
    "sns.barplot(data=atloc_4x_contrib_hist,\n",
    "            x='count', y='proportion', color=sns.color_palette()[1], ax=ax2)\n",
    "ax2.set_xlabel('Contribution Number to Location', fontsize=18)\n",
    "ax2.set_ylabel('Percentage of Total Contributions', fontsize=18)\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_yticks(range(0, 101, 10))\n",
    "ax2.set_title('4X Condition', fontsize=20)\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax2.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax2.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\") \n",
    "        \n",
    "# directed\n",
    "atloc_opp_dist_contrib_hist = atloc_opp_dist[atloc_opp_dist['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_opp_dist_contrib_hist = atloc_opp_dist_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_opp_dist_contrib_hist['total_count'] = atloc_opp_dist_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_opp_dist_contrib_hist['proportion'] = 100 * atloc_opp_dist_contrib_hist['total_count'] / sum(atloc_opp_dist_contrib_hist['total_count'])\n",
    "atloc_opp_dist_contrib_hist = pd.concat([atloc_opp_dist_contrib_hist, \n",
    "                                         pd.DataFrame({'count': [5], 'instances': [0], 'total_count': [0], 'proportion': [0.0]})])\n",
    "\n",
    "sns.barplot(data=atloc_opp_dist_contrib_hist,\n",
    "            x='count', y='proportion', color=sns.color_palette()[2], ax=ax3)\n",
    "ax3.set_xlabel('Contribution Number to Location', fontsize=18)\n",
    "ax3.set_ylabel('Percentage of Total Contributions', fontsize=18)\n",
    "ax3.set_ylim(0, 100)\n",
    "ax3.set_yticks(range(0, 101, 10))\n",
    "ax3.set_title('Directed Condition', fontsize=20)\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax3.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax3.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\") \n",
    "        \n",
    "# export plot\n",
    "fig.suptitle('Percentage of Total Contributions by Increasing Level of Fidelity', fontsize=24)\n",
    "output_fig = ax3.get_figure()\n",
    "output_fig.savefig('./graphs/data-scaffolding.png', dpi=300, transparent=True, bbox_inches='tight', pad_inches=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined scaffolding data\n",
    "combined_scaffolding_graph = pd.concat([atloc_opp_loc_contrib_hist, atloc_4x_contrib_hist, atloc_opp_dist_contrib_hist])[['count', 'total_count']]\n",
    "combined_scaffolding_graph = combined_scaffolding_graph.groupby('count')['total_count'].sum().reset_index()\n",
    "combined_scaffolding_graph['proportion'] = 100 * combined_scaffolding_graph['total_count'] / sum(combined_scaffolding_graph['total_count'])\n",
    "combined_scaffolding_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.barplot(data=combined_scaffolding_graph, color=sns.color_palette()[3],\n",
    "            x='count', y='proportion', ax=ax)\n",
    "ax.set_xlabel('Contribution Number to Location', fontsize=24)\n",
    "ax.set_ylabel('Percentage of Total Contributions', fontsize=24)\n",
    "\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 10))\n",
    "ax.set_title('Data Scaffolding Across All Conditions', fontsize=24)\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\", fontsize=20) \n",
    "        \n",
    "output_fig = ax.get_figure()\n",
    "output_fig.savefig('./graphs/data-scaffolding-all.png', dpi=300, transparent=True, bbox_inches='tight', pad_inches=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opportunistic\n",
    "atloc_opp_loc_contrib_hist = atloc_opp_loc[atloc_opp_loc['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_opp_loc_contrib_hist = atloc_opp_loc_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_opp_loc_contrib_hist['total_count'] = atloc_opp_loc_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_opp_loc_contrib_hist['proportion'] = 100 * atloc_opp_loc_contrib_hist['total_count'] / sum(atloc_opp_loc_contrib_hist['total_count'])\n",
    "atloc_opp_loc_contrib_hist['condition'] = 'Opportunistic'\n",
    "\n",
    "# 4X\n",
    "atloc_4x_contrib_hist = atloc_4x[atloc_4x['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_4x_contrib_hist = atloc_4x_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_4x_contrib_hist['total_count'] = atloc_4x_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_4x_contrib_hist['proportion'] = 100 * atloc_4x_contrib_hist['total_count'] / sum(atloc_4x_contrib_hist['total_count'])\n",
    "atloc_4x_contrib_hist['condition'] = '4X'\n",
    "\n",
    "# directed\n",
    "atloc_opp_dist_contrib_hist = atloc_opp_dist[atloc_opp_dist['remappedResponses'] == 'Valid Response'].groupby(['taskLocationId', 'locationName', 'locationType'])['taskLocationId'].count().reset_index(name='count')\n",
    "atloc_opp_dist_contrib_hist = atloc_opp_dist_contrib_hist.groupby('count')['taskLocationId'].count().reset_index(name='instances')\n",
    "atloc_opp_dist_contrib_hist['total_count'] = atloc_opp_dist_contrib_hist['instances'][::-1].cumsum()[::-1]\n",
    "atloc_opp_dist_contrib_hist['proportion'] = 100 * atloc_opp_dist_contrib_hist['total_count'] / sum(atloc_opp_dist_contrib_hist['total_count'])\n",
    "atloc_opp_dist_contrib_hist['condition'] = 'Directed'\n",
    "\n",
    "# combined plot data \n",
    "contribution_hist_data = pd.concat([atloc_opp_loc_contrib_hist, atloc_4x_contrib_hist, atloc_opp_dist_contrib_hist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(30, 8))\n",
    "\n",
    "sns.barplot(data=contribution_hist_data,\n",
    "            x='count', y='proportion', hue='condition', ax=ax)\n",
    "ax.set(xlabel='Contribution Number to Location',\n",
    "       ylabel='Percentage of Total Contributions')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks(range(0, 101, 5))\n",
    "ax.set_title('Directed')\n",
    "\n",
    "# Get current axis on current figure\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    if not math.isnan(height):\n",
    "        ax.text(p.get_x() + p.get_width() / 2, height + 1, '{:1.2f}%'.format(height), ha=\"center\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
